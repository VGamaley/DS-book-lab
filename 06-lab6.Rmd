
# Лабораторна робота №6. Побудова моделей класифікації {#lab_6}

__Мета:__ _Засвоєння базових принципів, знайомство з інструментами та набуття навичок побудови, eкспорту та імпорту моделей класифікації_ __на рівні технології__ на основі статистичного підходу та моделей машинного навчання засобами мови програмування R та за допомогою універсального інтерфейсу доступа до функцій машинного навчання пакета `caret`. 


## Що ви будете вміти?

* будувати моделі класифікації на основі статистичних моделей та моделей машинного навчання засобами мови R і пакету `caret` у середовищі IDE RStudio.

* виконувати експорт/імпорт навчених моделей до/з бази даних.


## Короткі теоретичні відомості

У рамках життєвого циклу процесу Data Mining згідно з методологією CRISP DM [@CRISP_DM], наступною за  фазою "Підготовка даних" (__Data Preparing__) є фаза "Моделювання" (__Modelling__) (рис. 1).     

Фаза моделювання призначена для вибору оптимального методу побудови моделей і настроювання його параметрів для отримання оптимальних рішень. На даній фазі вирішуються наступні задачі:  

- вибір методу моделювання;  
- генерація тестового проекту;  
- створення моделей;  
- оцінка моделей.   

Згідно з класичним розумінням технологія Data Mining передбачає побудову моделей, які можна віднести до одного з п'яти основних класів: _кластеризація (сегментація) та аналіз відхилень, регресія, класифікація, пошук асоціативних правил та аналіз послідовних шаблонів_.  

![_Рис. 1. Задача моделювання у складі Data Science-проекту_ [@r4ds] ](image/data-science-model.png)  


Задача сегментації та аналізу відхилень розглядалася нами як складова розвідувального аналізу даних [лаб. роб. №3](#lab_3) у рамках базового модулю.  

У рамках даного модулю буде розглянуто решту моделей. Дана лабораторна робота присвячена побудові моделей класифікації, що має багато спільного з побудовою моделей регресії (див. попередню [лаб. бар. №5](#lab_5).


### У чому полягає задача класифікації?

__Регресія і класифікація__

Між задачею класифікації і регресії існує багато спільного і в самому загальному вигляді їх можна розглядати як одну. Вона може бути сформульована наступим чином: припустимо, що об'єкт, який нас цікавить, описується вектором $n$ незалежних змінних $X_1, X_2, \dots, X_n$, які називаються предикторами. Існує деяка величина $Y$, яка також характеризує досліджуваний об'єкт, але залежить від $X_1, X_2, \dots, X_n$. Ми маємо колекцію наборів  спостережень незалежних змінних у вигляді матриці $X$ та залежної змінної у вигляді вектора відгуків $Y$: 

$$X=\begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1,n} \\
x_{21} & x_{22} & \cdots & x_{2,n} \\
\vdots & \vdots & \ddots & \cdots \\
x_{n1} & x_{n2} & \cdots & x_{n,n} \\
\end{bmatrix},$$  
та 
$$Y=\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n
\end{bmatrix}.$$  

На основі інформації, яку несуть в собі наявні значення $X$ та $Y$ необхідно побудувати модель, яка буде передбачати значення відгуку $y^*$ для будь-якого заданого набору незалежних змінних $x^*_1, x^*_2, \dots, x^*_n$  
Відмінність полягає у наступному (рис. 1): якщо значення відгуку носять дискретний характер, говорять про задачу _класифікації_, якщо неперервний -- має місце задача _регресії_.

![Рис. 1. Ілюстрація задач класифікації і регресії [@Paklin]](image/regression_classification.png) 

Таким чином логічно припустити, що і з точки зору математичного апарату і алгоритмів, що його реалізують при розв'язанні задач регресії і класифікації, має бути багато спільного, але, звичайно, мають бути і відмінності.  

У цій лабораторні роботі розглядаються методи і засоби побудови моделей регресії.


### Формальна постановка задачі класифікації

Сформулюємо задачу у [ймовірністній постановці](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D0%B4%D0%B0%D1%87%D0%B0_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8#%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BF%D0%BE%D1%81%D1%82%D0%B0%D0%BD%D0%BE%D0%B2%D0%BA%D0%B0_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B8). Припускається, що множина пар "об'єкт -- клас" $X \times Y$ є ймовірнісним простором з невідомою ймовірнісною мірою $\mathrm{P}$. Є скінченна навчальна вибірка спостережень $X^m = \big\{ (x_1, y_1), (x_2, y_2), ..., (x_m, y_m) \big\}$, згенерована згідно з ймовірнісною мірою $\mathrm{P}$. Потрібно побудувати алгоритм $a$: $X \rightarrow Y$, здатний класифікувати довільний об'єкт $x \in X$.

Як і в регресійному аналізі при побудові моделей класифікації використовуються як _статистичні_ підходи (_лінійний дискримінантний аналіз, логістична регресія_), так і підходи на основі машинного навчання (_дерева рішень, ліси дерев, нейронні мережі_).     

Як уже зазначалося, у роботі [@Fernandes] автори дослідили широке коло існуючих моделей класифікації і зробили висновок стосовно чотирьох класів моделей, які мають найбільшу точність:  

* __Випадковий ліс” (Random Forest)__;  
* __Машини опорних векторів (Support Vector Machines)__;  
* __Штучні нейронні мережі (Artificial Neural Networks)__;  
* __Бустінгові ансамблі моделей (Boosting Ensembles)__.  

Однак, питання побудови моделей класифікації, що можуть бути пояснені ([Explainable artificial intelligence)](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence), актуальне, як і у регресійному аналізі.    

Нижче будемо розглядати популярний потужній засіб для побудови моделей коасифікації і регресії `caret` (див. документацію на [CRAN](https://cran.r-project.org/)).      


### Пакет `caret`

Часто на практиці аналітику складно вибрати конкретний алгоритм машинного навчання, скласти план оптимізації параметрів, врахувати синтаксичні нюанси кожної функції і відстежити особливості її виконання. Крім того, процедури, що дозволяють реалізувати повний цикл розробки побудови прогнозних моделей, часто містяться в різних пакетах, що потребує часу і зусиль для їх освоєння. З метою інтеграції різних функцій і методів в рамках єдиної надбудови з метою узагальнення характерних для всіх моделей процедур обчислень доктор М. Кун із співробітниками  зробили спробу розробити універсальний інтерфейс, що надає доступ до основних алгоритмів машинного навчання, реалізованих на R та інших спеціалізованих статистичних системах (наприклад, [Weka](https://en.wikipedia.org/wiki/Weka_(machine_learning))). Розробники `caret` [@R-caret] поставили перед собою наступні завдання [@Shit_Mast]:

* урахування наявних синтаксичних відмінностей між використовуваними функціями R при побудові моделей класифікації та регресії і тестуванні їх можливостей для прогнозування;
* розвиток ряду напівавтоматичних, інтелектуальних підходів і критеріїв для оптимізації коефіцієнтів і параметрів багатьох з цих моделей, що мають бути налаштовані, з використанням алгоритмів ресемплінга;
* створення пакету з набором методів, який постійно розширюється;
* реалізація паралельних обчислень при підгонці моделей.  

Результатом цієї роботи став пакет `caret` (скорочення від Classification and Regression Training), який сьогодні став одним з найбільш популярних інструментів серед користувачів R, що займаються розробкою прогнозних моделей. Основні можливості пакету `caret` досить повно представлені в публікаціях розробників ([@Kuhn2008],  [@Kuhn2003], [@Khun_book], [@Kuhn2013]).  

З іншого боку, на практиці часто важливо вміти зберігати побудовані моделі в репозиторії і вилучати їх для подальшого використання безпосередньо в проектах. Для цього існують різні механізми, один з яких буде показано нижче.  

Таким чином, головна мета прикладу, який наведно нижче, зробити акцент на базових особливостях пакету `caret` при побудові моделі класифікації і показати механізм експорту/імпорту навченної моделі до реляційної бази даних з використанням механізму серилізації [@khramov].



## Приклад виконання індивідуального завдання

(_Експрес-версія. Далі буде_)

__Задача__. Використовуючи стандартний набір даних `iris`:

* побудувати модель класифікації;
* зберегти навчену модель у БД;
* реалізувати імпорт навченої моделі з БД.



### Навчання моделі

```{r}
library(caret)

# Завантажуємо дані

data <- iris

# Розділяємо дані на навчальну та тестову вибірки.

set.seed(1234)

trainIndex <- createDataPartition(1:nrow(data), times = 1, p = .8) #знаємо (1)

trainSet  <- data[trainIndex$Resample1,]
testSet   <- data[-trainIndex$Resample1,]

# Керування навчанням

fitCtrl <- trainControl(method = "repeatedcv",  # Кросс-валідація
                        number = 10,            # дані розбиваються на 10 частин
                        repeats = 5             # число повторень
)

# Навчання класиифікації за методом лінійного дискримінантного аналіза

model <- train(trainSet[,-5],trainSet[,5],
               method = 'lda',
               trControl = fitCtrl
)

# Навчена модель, яку має бути збережено:

# str(model)

fit <- model$finalModel
# str(fit)
```


### Експорт моделі до БД

Навчена модель -- це об'єкт класу `list` (список), тому завдання полягає в тому, щоби зберегти цей список у БД "єдиним куском", без декомпозиції його структури у відповідності до атрибутів таблиць БД. Для цього необхідно виконати його [серилізацію](https://ru.wikipedia.org/wiki/%D0%A1%D0%B5%D1%80%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F).  

Серилізуємо модель за допомогою спеціального метода `serialize` і потім трансформуємо її у єдиний блок символів.

```{r}
# Трансформуємо модель у набір символів

fit_char <- rawToChar(serialize(fit, NULL, TRUE))
nchar(fit_char) # скільки там символів?
```

Тепер в такому вигляді її може бути експортовано до БД. За допомогою БД `SQLite`  це можа зробити наступним чином.

```{r}
library(DBI)

# Створюємо базу даних.

# db <- dbConnect(RSQLite::SQLite(), dbname="models.sqlite")

# Видаляємо таблиці перед наступним тестовим запуском.
# dbGetQuery(db, "DROP TABLE IF EXISTS models")

# Створюємо таблицю з атрибутами:
#   'id',
#   'model' - собственно модель, сохраняемая как 'VARCHAR(2000)'.
# dbGetQuery(db, 'CREATE TABLE IF NOT EXISTS models
#            (id INT PRIMARY KEY,
#            model VARCHAR(2000))'
#           )

# Створємо data.frame для вставки у БД.

df <- data.frame(id = 1, mdl = fit_char)

# Вставляємо дані у таблицю БД.

# dbGetPreparedQuery(db, 'INSERT INTO models (model) values (:mdl)',
#                    bind.data = df)
# dbDisConnect(db)
```


### Імпорт моделі і работа з нею

Імпортуємо збережену у БД модель і застосуємо її для класифікації тестової вибірки. Для цього необхідно відновити модель у вигляді об'єкта R (`model2`). Для цього використовуємо зворотній метод `unserialize`.  

```{r}
# Вилучаємо дані з таблиці БД.

db <- dbConnect(RSQLite::SQLite(), dbname="models.sqlite")
df2 <- dbGetQuery(db, "SELECT * FROM models")

# Відновлюємо представлення моделі в R.

model2 <- unserialize(charToRaw(df2$model))
class(model2)

# Виконуємо класифікацію за допомогою відновленої моделі.

prediction <- predict(model2, newdata = testSet[,-5])

# Перервіряємо якість класифікації.

confusionMatrix(prediction$class, testSet[,5])

# Розриваємо зв'язок з БД.

dbDisconnect(db)

# Видяляємо таблиці перед наступним тестовим запуском.
# dbGetQuery(db, "DROP TABLE IF EXISTS models")
```



### Індивідуальні завдання на лабораторну роботу


Видає викладач.
