[["index.html", "Data Science  R.   (draft version)  1 ", " Data Science  R.   (draft version) ©  . . 2022-03-14  1             ,                     . : , . . .  .  ,      ,              R,      ,  vignetts      CRAN.        .       CRISP DM (wikipedia 2018a)               :    ,   , ,    Data Science-.         vnsidorenko@gmail.com. References "],["modul1.html", " 2  1. .   1.    Data Science- 2.1    ? 2.2    2.3   Markdown-", "  2  1. .   1.    Data Science- :      Data Science-   R-Studio (RStudio Team 2020)         R (R Core Team 2021),  RMarkdown     LaTeX. 2.1    ?  / ,   ,        R   IDE RStudio.    (  html, pdf, doc)   ,     ( ,  /   . .).    LaTeX   , ,  : \\(y(x)=b_0+b_1x+b_2x^2\\).      BibTeX,      References,    . 2.2    2.2.1   Data Science-? - Data Science- (   Data Mining-)        CRISP DM (wikipedia 2018a).    CRISP-DM 1.0    Data Mining      (. 1): -  - (business understanding); -   (data understanding); -   (data preparation); -  (modeling); -  (evaluation); -  (deployment). . 1.    Data Mining    CRISP   -   : -  -; -  ; -   Data Mining; -   .      : -   ; -  ; -  ; -   .        ,        .     : -  ; -  ; -  ; -  ; -  .   -               .      : -   ; -   ; -  ; -  .   -          ,      -.     : -  ; -  ; -   .     .        ,     - Data Science-     (Garrett Grolemund 2018) (. 2). . 2.   Data Science- (Garrett Grolemund 2018)     (Import)        -  (, ,        . .)   .   (Tidy)        ,   .           -, ,  , -.            (Wrangling, Munging),    , ,    (Missing Value Emputation),    (data reduction),    (Transforming)  . . , Tiding+Transforming=Wrangling(Munging).   -- (Transform-Visualise-Model)   Data Mining-,                ,    ,      ,     ,   .        (Understanding) ,   ,            .            (ommunicate)   ,    ,        , ,   .    Data Science-   ,         ,    ,      -     ,   ,      .     R     , IDE RStudio             Data Science-,      . 2.2.2                 : , ,  ,   ,     : .doc, pdf, .html .          -                     .     Data Science,               Data Science.   (Literate Programming)  ,    ,                 .            ,      ,     ,        .         (. Markdown, YAML, HTML, LaTeX),        ,       .  ,     ,            .       (IDE, Integrated Development Environment,   ),      .                (. 3): IDE R Studio (RStudio Team 2020)    ;    R (R Core Team 2021)            ;  RMarkdown (Allaire et al. 2022)        Markdown; (.(sandino 2013)    RStudio: Help\\Cheat_Sheets);    . ;  . R Markdown: .    ;    LaTex     . . 3.              (literate programming) 2.2.3 Markdown  RMarkdown Markdown (: [])     ,                structurally valid XHTML  HTML.  ,  GitHub, Reddit  Stack Overflow  Markdown     . R Markdown (Yihui Xie 2018)   R,     Markdown-   IDE RStudio           R   .                   .    ,  R, Python, ++, HTML, SQL, Stan.   Pandoc     html, doc  pdf    -, , , . 2.2.4  R      CRAN,      R.   R   GUI,     . ,   Contributed,      ,   .         R      . ,     . 2.2.5  RStudio      ,     RMarkdown    ,   IDE RStudio. 2.2.6  RMarkdown-  RStudio.  RMarkdown-   R Notebook,    . 2.2.7          Ctrl+Shift+K. 2.3   Markdown- 2.3.1      \\(y(x)=b_ox+b_1+b_2x^2\\)   \\(x \\in [x_1;x_2]\\). 2.3.2     R Markdown,     .  RMarkdown-.    YAML- ,       (. 4). . 4.  YAML-  ,         LaTeX     .   RMarkdown-      $: $y(x)=b_ox+b_1+b_2x^2$    R      ,    @ref(fig:fig_1): #    b0 &lt;- 2 b1 &lt;- 3 b2 &lt;- 1.57 #    x &lt;- seq(-1, 1, .1) y &lt;- b0 + b1 * x + b2 * x^2 plot(x, y, type = &quot;l&quot;, col = &quot;red&quot;, main = &quot; &quot;, xlab = &quot;x&quot;, ylab = &quot;y&quot; ) points(x, y, col = &quot;blue&quot;) (#fig:fig_1)Example fig. df &lt;- data.frame(x = x, y = y) #       rio (Chan and Leeper 2021)   ()    ( ). # install.packages(&quot;rio&quot;) #   library(rio) #   export(df, &quot;data/data.csv&quot;)           @ref(tab:tab_1). dfNew &lt;- import(&quot;data/data.csv&quot;) #   knitr knitr::kable(head(dfNew), caption = &quot;_. 1.   _&quot;) (#tab:tab_1). 1.    x y -1.0 0.5700 -0.9 0.5717 -0.8 0.6048 -0.7 0.6693 -0.6 0.7652 -0.5 0.8925 #   stargazer # stargazer::stargazer(head(dfNew), # type = &quot;html&quot;, # summary = FALSE, # title = &quot;_. 1.   _&quot;) #   xtable # print(xtable::xtable(head(dfNew), # type = &quot;html&quot;, # html.table.attributes=&quot;border=0&quot;, # summary = FALSE, # caption = &quot;_. 1.   _&quot;))   . . 2.     \\(b_0\\) 2 \\(b_1\\) 3 \\(b_2\\) 1.57 \\(x_1\\) -1 \\(x_2\\) 1 2.3.3       . 2.3.4       ggplot2 (Wickham 2009).  ,    ,     %&gt;%   ggplot2.      ggplot2. (Wickham et al. 2021) References "],["lab_2.html", " 3   2.   3.1    ? 3.2    3.3    ", "  3   2.   :  ,         (wrangle)    R    tidyverse (Wickham 2021b). 3.1    ?       ,       R   IDE RStudio.             tidyr (Wickham and Girlich 2022).     R   IDE RStudio    dplyr (Wickham et al. 2022)     %&gt;%. 3.2    3.2.1    ? Wrangle     ,                   : Tidy + Transform = Wrangle. (Garrett Grolemund 2018) (. 1).      ,   , ,      . . 1.       Data Science- (Garrett Grolemund 2018) 3.2.2       (Import)        -  (, ,        . .)   .           (    (Tabular Data)   (Non-Tabular Data)):         ;      ,     ,        ;   - ,  ,    .         R     ,      .  ,    ,     rio (Chan et al. 2018),    . . 1. # install_formats() #    rio library(rio) df &lt;- data.frame(x = 1:5, y = rnorm(5)) export(df, &quot;data/df_data_frame.txt&quot;) dfImp &lt;- import(&quot;data/df_data_frame.txt&quot;) dfImp ## x y ## 1 1 -0.7120003 ## 2 2 -0.8249593 ## 3 3 0.3828742 ## 4 4 -0.6068955 ## 5 5 -0.9761304                   . data(&quot;mtcars&quot;) #    mtcars # head(mtcars) export(head(mtcars), &quot;data/mtcars.dta&quot;) convert(&#39;data/mtcars.dta&#39;, &#39;data/mtcars.csv&#39;) import(&quot;data/mtcars.csv&quot;) ## mpg cyl disp hp drat wt qsec vs am gear carb ## 1 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## 2 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## 3 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## 4 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## 5 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## 6 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 3.2.2.1       dplyr (Wickham et al. 2022)          .        dbplyr (Wickham, Girlich, and Ruiz 2021).            ,     ,      data.frame (. ). dbplyr         ,     SQL. ,        SQL!    dbplyr     DBI.  DBI   ,   dbplyr      ,      . DBI     dbplyr,         ,     : RMySQL (Ooms et al. 2021)   MySQL  MariaDB; RPostgreSQL (Conway et al. 2021)   Postgres  Redshift; RSQLite (Müller et al. 2022)  SQLite- ; odbc (Hester and Wickham 2021)           ; bigrquery (Wickham and Bryan 2021)   Google BigQuery.         SQLite,        R.     -         .    SQLite  dplyr  :     ,     : library(dbplyr) library(dplyr) library(RSQLite) # my_db &lt;- src_sqlite(&quot;data/my_db.sqlite3&quot;, create = T) my_db    ,      flights (   (Wickham 2021a))     copy_to().       ,      ,         ,       R. library(nycflights13) # flights_sqlite &lt;- copy_to(my_db, flights, temporary = FALSE, # indexes = list(c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), &quot;carrier&quot;, &quot;tailnum&quot;)) # head(flights_sqlite)           DBConnect,     DBI (R Special Interest Group on Databases (R-SIG-DB), Wickham, and Muller 2021). con &lt;- DBI::dbConnect(RSQLite::SQLite(), path = &quot;data/my_db.sqlite3&quot;) flights_sqlite &lt;- copy_to(con, nycflights13::flights, &quot;flights&quot;, temporary = FALSE, indexes = list( c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), &quot;carrier&quot;, &quot;tailnum&quot;, &quot;dest&quot; ) ) head(flights_sqlite) ## # Source: lazy query [?? x 19] ## # Database: sqlite 3.37.2 [] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## # ... with 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt; DBI::dbDisconnect(con)        ,    RStudio (Wickham, Girlich, and Ruiz 2021),       RStudio,         dplyr.       ,         ,     reader (Cooper 2017)           read_*, col_*, parse_*,   (strings),   (factors),   - (data-time) (.  Data import with readr, readxl, and googlesheets4 cheatsheet),     tidyvers. 3.2.3      3.2.3.1     (tidy data)?      (Tidy)        ,   .           -, ,  , -.  tidyvers      ,     tibbles,     data.frame.      tibble (Müller and Wickham 2021),    S3     . tibbles   data.frame      (.  ).    (Wickham and Girlich 2022),     tidyvers,     (Garrett Grolemund 2018). (   . (Wickham and Girlich 2022),    ).    ,     :      ;       ;        . . 2.   ,      (Garrett Grolemund 2018)       ?     :            ,   ,    ,        ;     R             ,   ,        .      ,    . library(tidyverse) #    10000 table1 %&gt;% #    mutate(rate = cases / population * 10000) #    ## # A tibble: 6 x 5 ## country year cases population rate ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Afghanistan 1999 745 19987071 0.373 ## 2 Afghanistan 2000 2666 20595360 1.29 ## 3 Brazil 1999 37737 172006362 2.19 ## 4 Brazil 2000 80488 174504898 4.61 ## 5 China 1999 212258 1272915272 1.67 ## 6 China 2000 213766 1280428583 1.67 #     table1 %&gt;% count(year, wt = cases) ## # A tibble: 2 x 2 ## year n ## &lt;int&gt; &lt;int&gt; ## 1 1999 250740 ## 2 2000 296920   %&gt;%     .    :  sin(cos(x))     x %&gt;% cos() %&gt;% sin().           ggplot2 (Wickham et al. 2021)   . #        library(ggplot2) ggplot(table1, aes(year, cases)) + geom_line(aes(group = country), colour = &quot;grey50&quot;) + geom_point(aes(colour = country)) # table1 %&gt;% # mutate(rate = cases / population * 10000) %&gt;% # ggplot(aes(year, rate)) + # geom_line(aes(group = country), colour = &quot;grey50&quot;) + # geom_point(aes(colour = country))    .     rate       . 3.2.3.2  Spreading and Gathering          :         ;        .        tidyr   gather() spread(). 3.2.3.2.1 Gathering     ,         ,   .  table4a:   1999  2000    ,      ,   . table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766      (gather)       (. 3). . 3  table4    (Garrett Grolemund 2018) table4a %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;cases&quot;) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 ## 2 Brazil 1999 37737 ## 3 China 1999 212258 ## 4 Afghanistan 2000 2666 ## 5 Brazil 2000 80488 ## 6 China 2000 213766         ,    . tidy4a &lt;- table4a %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;cases&quot;) tidy4b &lt;- table4b %&gt;% gather(`1999`, `2000`, key = &quot;year&quot;, value = &quot;population&quot;) dplyr::left_join(tidy4a, tidy4b) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Brazil 1999 37737 172006362 ## 3 China 1999 212258 1272915272 ## 4 Afghanistan 2000 2666 20595360 ## 5 Brazil 2000 80488 174504898 ## 6 China 2000 213766 1280428583    .   ,    tidy4a  tidy4b    . 3.2.3.2.2 Spreading    . ,   (spreading) ,       (. 4). . 4  table2    (Garrett Grolemund 2018) . table2 ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 table2 %&gt;% spread(key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 3.2.3.3  Separating  Uniting     ,       .      (separating)   (. .5). . 5  table3       (Garrett Grolemund 2018) table3 ## # A tibble: 6 x 3 ## country year rate ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 table3 %&gt;% separate(rate, into = c(&quot;cases&quot;, &quot;population&quot;)) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583    separate()  unite(). table5 %&gt;% unite(new, century, year, sep = &quot;&quot;) ## # A tibble: 6 x 3 ## country new rate ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 3.2.3.4     (missing value)       :  (  NA, Not Available)   (    ).    .   ,   . stocks &lt;- tibble( year = c(2015, 2015, 2015, 2015, 2016, 2016, 2016), qtr = c( 1, 2, 3, 4, 2, 3, 4), return = c(1.88, 0.59, 0.35, NA, 0.92, 0.17, 2.66) ) stocks ## # A tibble: 7 x 3 ## year qtr return ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 1 1.88 ## 2 2015 2 0.59 ## 3 2015 3 0.35 ## 4 2015 4 NA ## 5 2016 2 0.92 ## 6 2016 3 0.17 ## 7 2016 4 2.66     2015       .        ,   ,       . stocks %&gt;% spread(year, return) ## # A tibble: 4 x 3 ## qtr `2015` `2016` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.88 NA ## 2 2 0.59 0.92 ## 3 3 0.35 0.17 ## 4 4 NA 2.66          complete(). stocks %&gt;% complete(year, qtr) ## # A tibble: 8 x 3 ## year qtr return ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2015 1 1.88 ## 2 2015 2 0.59 ## 3 2015 3 0.35 ## 4 2015 4 NA ## 5 2016 1 NA ## 6 2016 2 0.92 ## 7 2016 3 0.17 ## 8 2016 4 2.66      :   ,      ,    . stocks %&gt;% spread(year, return) %&gt;% gather(year, return, `2015`:`2016`, na.rm = TRUE) ## # A tibble: 6 x 3 ## qtr year return ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2015 1.88 ## 2 2 2015 0.59 ## 3 3 2015 0.35 ## 4 2 2016 0.92 ## 5 3 2016 0.17 ## 6 4 2016 2.66  ,   ,    fill(),    ,      : df &lt;- data.frame(Month = 1:12, Year = c(2000, rep(NA, 11))) df ## Month Year ## 1 1 2000 ## 2 2 NA ## 3 3 NA ## 4 4 NA ## 5 5 NA ## 6 6 NA ## 7 7 NA ## 8 8 NA ## 9 9 NA ## 10 10 NA ## 11 11 NA ## 12 12 NA df %&gt;% fill(Year) ## Month Year ## 1 1 2000 ## 2 2 2000 ## 3 3 2000 ## 4 4 2000 ## 5 5 2000 ## 6 6 2000 ## 7 7 2000 ## 8 8 2000 ## 9 9 2000 ## 10 10 2000 ## 11 11 2000 ## 12 12 2000 3.2.4       .            :    ,     ,   ,    .  (Transform)         .  R       ,     ,           dplyr (Wickham et al. 2022)  ,      , .            (Wickham et al. 2022).   , dplyr    ,     ,         : mutate()   ,     . select()   ( )    . filter()   ()    . summarise()      . arrange()   .          group_by(),    -   .        dplyr       .        purrr (Henry and Wickham 2020)    ,     tidyverse.    , dplyr   ,    ,    .  ,                     R. ,        SQL-,     ,         . #    library(dplyr) starwars %&gt;% filter(species == &quot;Droid&quot;) ## # A tibble: 6 x 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 C-3PO 167 75 &lt;NA&gt; gold yellow 112 none masculi~ ## 2 R2-D2 96 32 &lt;NA&gt; white, blue red 33 none masculi~ ## 3 R5-D4 97 32 &lt;NA&gt; white, red red NA none masculi~ ## 4 IG-88 200 140 none metal red 15 none masculi~ ## 5 R4-P17 96 NA none silver, red red, blue NA none feminine ## 6 BB8 NA NA none none black NA none masculi~ ## # ... with 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, films &lt;list&gt;, ## # vehicles &lt;list&gt;, starships &lt;list&gt; #    starwars %&gt;% select(name, ends_with(&quot;color&quot;)) ## # A tibble: 87 x 4 ## name hair_color skin_color eye_color ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Luke Skywalker blond fair blue ## 2 C-3PO &lt;NA&gt; gold yellow ## 3 R2-D2 &lt;NA&gt; white, blue red ## 4 Darth Vader none white yellow ## 5 Leia Organa brown light brown ## 6 Owen Lars brown, grey light blue ## 7 Beru Whitesun lars brown light blue ## 8 R5-D4 &lt;NA&gt; white, red red ## 9 Biggs Darklighter black light brown ## 10 Obi-Wan Kenobi auburn, white fair blue-gray ## # ... with 77 more rows #         starwars %&gt;% mutate(name, bmi = mass / ((height / 100) ^ 2)) %&gt;% select(name:mass, bmi) ## # A tibble: 87 x 4 ## name height mass bmi ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Luke Skywalker 172 77 26.0 ## 2 C-3PO 167 75 26.9 ## 3 R2-D2 96 32 34.7 ## 4 Darth Vader 202 136 33.3 ## 5 Leia Organa 150 49 21.8 ## 6 Owen Lars 178 120 37.9 ## 7 Beru Whitesun lars 165 75 27.5 ## 8 R5-D4 97 32 34.0 ## 9 Biggs Darklighter 183 84 25.1 ## 10 Obi-Wan Kenobi 182 77 23.2 ## # ... with 77 more rows #   starwars %&gt;% arrange(desc(mass)) ## # A tibble: 87 x 14 ## name height mass hair_color skin_color eye_color birth_year sex gender ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Jabba D~ 175 1358 &lt;NA&gt; green-tan~ orange 600 herm~ mascu~ ## 2 Grievous 216 159 none brown, wh~ green, y~ NA male mascu~ ## 3 IG-88 200 140 none metal red 15 none mascu~ ## 4 Darth V~ 202 136 none white yellow 41.9 male mascu~ ## 5 Tarfful 234 136 brown brown blue NA male mascu~ ## 6 Owen La~ 178 120 brown, gr~ light blue 52 male mascu~ ## 7 Bossk 190 113 none green red 53 male mascu~ ## 8 Chewbac~ 228 112 brown unknown blue 200 male mascu~ ## 9 Jek Ton~ 180 110 brown fair blue NA male mascu~ ## 10 Dexter ~ 198 102 none brown yellow NA male mascu~ ## # ... with 77 more rows, and 5 more variables: homeworld &lt;chr&gt;, species &lt;chr&gt;, ## # films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; #        species starwars %&gt;% group_by(species) %&gt;% summarise( n = n(), mass = mean(mass, na.rm = TRUE) ) %&gt;% filter(n &gt; 1) ## # A tibble: 9 x 3 ## species n mass ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Droid 6 69.8 ## 2 Gungan 3 74 ## 3 Human 35 82.8 ## 4 Kaminoan 2 88 ## 5 Mirialan 2 53.1 ## 6 Twi&#39;lek 2 55 ## 7 Wookiee 2 124 ## 8 Zabrak 2 80 ## 9 &lt;NA&gt; 4 48  tidyr  dplyr    ( stringr  forcats),        : lubridate (Spinu, Grolemund, and Wickham 2021)      -. hms (Muller 2021)     . blob [R-blob]  ,    (blob) .    .    ,        (Hadley Wickham 2018).      dplyr  RStudio. 3.3     3.3.1     ,   SQLite.         nycflights13    -  2013 .  : (year, month, day), carrier, tailnum, dest.  RMarkdown-,            :   year:day, dep_delay, arr_delay   flights.       (dep_delay)   240 .      (dep_time)       (dest).           100       ;       .                ;          (  ggplot2).           . 3.3.2     ,   SQLite. # my_db &lt;- src_sqlite(&quot;data/my_db.sqlite3&quot;, create = T)   .         nycflights13    -  2013 .  : (year, month, day), carrier, tailnum, dest. con &lt;- DBI::dbConnect(RSQLite::SQLite(), path = &quot;data/my_db.sqlite3&quot;) flights_sqlite &lt;- copy_to(con, nycflights13::flights, &quot;flights&quot;, temporary = FALSE, indexes = list( c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), &quot;carrier&quot;, &quot;tailnum&quot;, &quot;dest&quot; ) ) head(flights_sqlite) ## # Source: lazy query [?? x 19] ## # Database: sqlite 3.37.2 [] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 819 ## 2 2013 1 1 533 529 4 850 830 ## 3 2013 1 1 542 540 2 923 850 ## 4 2013 1 1 544 545 -1 1004 1022 ## 5 2013 1 1 554 600 -6 812 837 ## 6 2013 1 1 554 558 -4 740 728 ## # ... with 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, ## # tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;   year:day, dep_delay, arr_delay   flights. flights_sqlite %&gt;% select(year:day, dep_delay, arr_delay) ## # Source: lazy query [?? x 5] ## # Database: sqlite 3.37.2 [] ## year month day dep_delay arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 ## 2 2013 1 1 4 20 ## 3 2013 1 1 2 33 ## 4 2013 1 1 -1 -18 ## 5 2013 1 1 -6 -25 ## 6 2013 1 1 -4 12 ## 7 2013 1 1 -5 19 ## 8 2013 1 1 -3 -14 ## 9 2013 1 1 -3 -8 ## 10 2013 1 1 -2 8 ## # ... with more rows       (dep_delay)   240 . flights_sqlite %&gt;% filter(dep_delay &gt; 240) ## # Source: lazy query [?? x 19] ## # Database: sqlite 3.37.2 [] ## year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 848 1835 853 1001 1950 ## 2 2013 1 1 1815 1325 290 2120 1542 ## 3 2013 1 1 1842 1422 260 1958 1535 ## 4 2013 1 1 2115 1700 255 2330 1920 ## 5 2013 1 1 2205 1720 285 46 2040 ## 6 2013 1 1 2343 1724 379 314 1938 ## 7 2013 1 2 1332 904 268 1616 1128 ## 8 2013 1 2 1412 838 334 1710 1147 ## 9 2013 1 2 1607 1030 337 2003 1355 ## 10 2013 1 2 2131 1512 379 2340 1741 ## # ... with more rows, and 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;      (dep_time)       (dest). flights_sqlite %&gt;% group_by(dest) %&gt;% summarise(delay = mean(dep_time)) ## Warning: Missing values are always removed in SQL. ## Use `mean(x, na.rm = TRUE)` to silence this warning ## This warning is displayed only once per session. ## # Source: lazy query [?? x 2] ## # Database: sqlite 3.37.2 [] ## dest delay ## &lt;chr&gt; &lt;dbl&gt; ## 1 ABQ 2006. ## 2 ACK 1033. ## 3 ALB 1627. ## 4 ANC 1635. ## 5 ATL 1293. ## 6 AUS 1521. ## 7 AVL 1175. ## 8 BDL 1490. ## 9 BGR 1690. ## 10 BHM 1944. ## # ... with more rows           100       ;       . tailnum_delay_sqlite &lt;- flights_sqlite %&gt;% group_by(tailnum) %&gt;% summarise( delay = mean(arr_delay), n = n() ) %&gt;% arrange(desc(delay)) %&gt;% filter(n &gt; 100)                ;          (  ggplot2). library(ggplot2) planes &lt;- group_by(flights, tailnum) delay &lt;- summarise(planes, count = n(), dist = mean(distance, na.rm = TRUE), delay = mean(arr_delay, na.rm = TRUE)) delay &lt;- filter(delay, count &gt; 20, dist &lt; 2000) ggplot(delay, aes(dist, delay)) + geom_point(aes(size = count), alpha = 1/2) + geom_smooth() + scale_size_area() ## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39; ## Warning: Removed 1 rows containing non-finite values (stat_smooth). ## Warning: Removed 1 rows containing missing values (geom_point).           . destinations &lt;- group_by(flights, dest) summarise(destinations, planes = n_distinct(tailnum), flights = n() ) ## # A tibble: 105 x 3 ## dest planes flights ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 ABQ 108 254 ## 2 ACK 58 265 ## 3 ALB 172 439 ## 4 ANC 6 8 ## 5 ATL 1180 17215 ## 6 AUS 993 2439 ## 7 AVL 159 275 ## 8 BDL 186 443 ## 9 BGR 46 375 ## 10 BHM 45 297 ## # ... with 95 more rows DBI::dbDisconnect(con) 3.3.3       . References "],["lab_3.html", " 4   3.   .  4.1    ? 4.2    4.3    ", "  4   3.   .  :  ,        ()      R    dplyr, ggplot2, desctable, \"GGally\", \"corrplot\", \"PerformanceAnalytics\", \"FactoMineR\", \"factoextra\", \"funModeling\", \"desctable\", \"ade4\", \"psych\", \"smacof\", \"WVPlots\", \"caret\", \"car\". 4.1    ?        R   IDE RStudio.   . 4.2    4.2.1     ?      Data Mining    CRISP DM (wikipedia 2018a),        (Understanding) (. 1).               .        ,         (Exploratory data analysis, EDA).        ,     ,   ,       /    : , , ,   .. (wikipedia 2018b) . 1.       Data Science- (Garrett Grolemund 2018)  EDA     ,      :                         :             :  ,  ,    .     ,    :          ,       ,         .     -  ,       ,         .        :     ,        . (Garrett Grolemund 2018).          : ,   . 4.2.2    ,     ,   ,         .         ,      .          (Garrett Grolemund 2018):        ?        ? 4.2.2.1   (Variation)           .        ;      ,     .     ,       (,    )      (,      ).        ,     .          . 4.2.2.1.1        . library(tidyverse) library(ggplot2) ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut))        , , : diamonds %&gt;% count(cut) ## # A tibble: 5 x 2 ## cut n ## &lt;ord&gt; &lt;int&gt; ## 1 Fair 1610 ## 2 Good 4906 ## 3 Very Good 12082 ## 4 Premium 13791 ## 5 Ideal 21551      : ggplot(data = diamonds) + geom_histogram(mapping = aes(x = carat), binwidth = 0.5)   ,   ,    : diamonds %&gt;% count(cut_width(carat, 0.5)) ## # A tibble: 11 x 2 ## `cut_width(carat, 0.5)` n ## &lt;fct&gt; &lt;int&gt; ## 1 [-0.25,0.25] 785 ## 2 (0.25,0.75] 29498 ## 3 (0.75,1.25] 15977 ## 4 (1.25,1.75] 5313 ## 5 (1.75,2.25] 2002 ## 6 (2.25,2.75] 322 ## 7 (2.75,3.25] 32 ## 8 (3.25,3.75] 5 ## 9 (3.75,4.25] 4 ## 10 (4.25,4.75] 1 ## 11 (4.75,5.25] 1       : smaller &lt;- diamonds %&gt;% filter(carat &lt; 3) ggplot(data = smaller, mapping = aes(x = carat)) + geom_histogram(binwidth = 0.1)          : ggplot(data = smaller, mapping = aes(x = carat, colour = cut)) + geom_freqpoly(binwidth = 0.1)  ,    ,       ?        ? *         :     ? ?    ? ?    ?      ?    ?  ,      :        ,      ?     3 ? ggplot(data = smaller, mapping = aes(x = carat)) + geom_histogram(binwidth = 0.01) 4.2.2.1.2          (outliers)        ,     ,    . ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5)  ,   ,     : ggplot(diamonds) + geom_histogram(mapping = aes(x = y), binwidth = 0.5) + coord_cartesian(ylim = c(0, 50))     ,      : unusual &lt;- diamonds %&gt;% filter(y &lt; 3 | y &gt; 20) %&gt;% select(price, x, y, z) %&gt;% arrange(y) unusual ## # A tibble: 9 x 4 ## price x y z ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5139 0 0 0 ## 2 6381 0 0 0 ## 3 12800 0 0 0 ## 4 15686 0 0 0 ## 5 18034 0 0 0 ## 6 2130 0 0 0 ## 7 2130 0 0 0 ## 8 2075 5.15 31.8 5.12 ## 9 12210 8.09 58.9 8.06 4.2.2.1.3   (Missing values)            (NA).        :                 .  ggplot2    : diamonds ## # A tibble: 53,940 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.29 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ## 7 0.24 Very Good I VVS1 62.3 57 336 3.95 3.98 2.47 ## 8 0.26 Very Good H SI1 61.9 55 337 4.07 4.11 2.53 ## 9 0.22 Fair E VS2 65.1 61 337 3.87 3.78 2.49 ## 10 0.23 Very Good H VS1 59.4 61 338 4 4.05 2.39 ## # ... with 53,930 more rows diamonds2 &lt;- diamonds %&gt;% mutate(y = ifelse(y &lt; 3 | y &gt; 20, NA, y)) ggplot(data = diamonds2, mapping = aes(x = x, y = y)) + geom_point() ## Warning: Removed 9 rows containing missing values (geom_point).    ,      ,      . ,  nycflights13::flights,     dep_time ( ) ,    . , ,             .    ,     is.na(): nycflights13::flights %&gt;% mutate( cancelled = is.na(dep_time), sched_hour = sched_dep_time %/% 100, sched_min = sched_dep_time %% 100, sched_dep_time = sched_hour + sched_min / 60 ) %&gt;% ggplot(mapping = aes(sched_dep_time)) + geom_freqpoly(mapping = aes(colour = cancelled), binwidth = 1/4) 4.2.2.2        ,     .  (Covariation)          .            . 4.2.2.2.1            ,          ,     .    geom_freqpoly()       ,     .  ,        ,  ,     . ,  ,        : ggplot(data = diamonds, mapping = aes(x = price)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)     ,         : ggplot(diamonds) + geom_bar(mapping = aes(x = cut))       ,     Y.  ,   ,    ,    . ggplot(data = diamonds, mapping = aes(x = price, y = ..density..)) + geom_freqpoly(mapping = aes(colour = cut), binwidth = 500)    ,        (fair).        .         (boxplot, box and wiskers plot),   ,    .            ,     (. 3). . 3.   (Garrett Grolemund 2018)         : ggplot(data = diamonds, mapping = aes(x = cut, y = price)) + geom_boxplot() 4.2.2.2.2            :   ,    . : ggplot(data = diamonds) + geom_count(mapping = aes(x = cut, y = color))   ,       ,    . 4.2.2.3  FunModelling       FunModelling (Casas 2020),       ,       ,    ,    .  df_status() :      describe() :     () freq():   (  ). profileing_num():     () plot_num () :     () 4.2.3      (Dimensionality reduction)          .         .         (),                    ,    . ( ).               . ( ). (          ).         .      ?       ,  ,      , ,   ,  .       ,     ,  PCA (wikipedia 2018c). 4.2.3.1       (PCA)  (wikipedia 2018c),      \\(X\\): \\[ X=\\begin{pmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{pmatrix} \\]   : \\[ var(X) = \\Sigma = \\begin{pmatrix} \\sigma_{1}^2 &amp; \\sigma_{12} &amp; \\ldots &amp; \\sigma_{1p}\\\\ \\sigma_{21} &amp; \\sigma_{2}^2 &amp; \\ldots &amp; \\sigma_{2p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\sigma_{p1} &amp; \\sigma_{p2} &amp; \\ldots &amp; \\sigma_{p}^2 \\end{pmatrix} \\]  PCA (Science 2020)    \\(k\\)   \\(p\\)  \\(X\\),    .     : \\(Y_1 = a_{11} X_1 + a_{12} X_2 + \\cdots + a_{1p} X_p\\) \\(Y_2 = a_{21} X_1 + a_{22} X_2 + \\cdots + a_{2p} X_p\\) \\(\\vdots\\) \\(Y_k = a_{k1} X_1 + a_{k2} X_2 + \\cdots + a_{kp} X_p\\)   \\(\\sum\\limits_{i=1}^pa_{1i}^2=1\\)  . .     \\(var(Y_1)=a_1&#39;\\Sigma a_1\\),  \\(\\Sigma\\)   .      . .  .     \\(a_i&#39;=(a_{i1}, a_{i2},...,a_{ip})&#39;,\\;i=\\overline{1,p}\\)      \\(\\Sigma\\),    \\(i\\)-       : \\(var(Y_i)=\\lambda_i\\).     \\(\\sum\\limits_{i=1}^p\\lambda_{i}.\\)    (PCA)          ()   ,     ,       .           ,        ,       .   R       ,  PCA. 4.3     4.3.1          (. Iris flower data set).       150      - Iris setosa, Iris virginica  Iris versicolor,  50   .       ( ):     (. sepal length);     (. sepal width);     (. petal length);     (. petal width).       .      :    ?    .     ?  ,    ?    ,           4?      .           ?  ,         .        . 4.3.2         : iris %&gt;% head() ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa # iris %&gt;% # desctable()     . #    iris %&gt;% df_status() ## variable q_zeros p_zeros q_na p_na q_inf p_inf type unique ## 1 Sepal.Length 0 0 0 0 0 0 numeric 35 ## 2 Sepal.Width 0 0 0 0 0 0 numeric 23 ## 3 Petal.Length 0 0 0 0 0 0 numeric 43 ## 4 Petal.Width 0 0 0 0 0 0 numeric 22 ## 5 Species 0 0 0 0 0 0 factor 3   ?       :                            ,              .       . #     iris %&gt;% plot_num() ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. iris %&gt;% profiling_num() ## variable mean std_dev variation_coef p_01 p_05 p_25 p_50 p_75 ## 1 Sepal.Length 5.843333 0.8280661 0.1417113 4.400 4.600 5.1 5.80 6.4 ## 2 Sepal.Width 3.057333 0.4358663 0.1425642 2.200 2.345 2.8 3.00 3.3 ## 3 Petal.Length 3.758000 1.7652982 0.4697441 1.149 1.300 1.6 4.35 5.1 ## 4 Petal.Width 1.199333 0.7622377 0.6355511 0.100 0.200 0.3 1.30 1.8 ## p_95 p_99 skewness kurtosis iqr range_98 range_80 ## 1 7.255 7.700 0.3117531 2.426432 1.3 [4.4, 7.7] [4.8, 6.9] ## 2 3.800 4.151 0.3157671 3.180976 0.5 [2.2, 4.151] [2.5, 3.61] ## 3 6.100 6.700 -0.2721277 1.604464 3.5 [1.149, 6.7] [1.4, 5.8] ## 4 2.300 2.500 -0.1019342 1.663933 1.5 [0.1, 2.5] [0.2, 2.2] # dimnames(iris)   ?    \"Sepal.Length\", \"Sepal.Width\"   ,   . ,          ,        .        ? -,    ,         , -,     , , ,     ,                  , , ,   .             ,        .    \"Petal.Length\", \"Petal.Width\"     ,    ,          ,           ;          ,     ,   .     ,       .     ,    .        . #   iris %&gt;% select(-Species) %&gt;% cor() %&gt;% corrplot(order = &quot;hclust&quot;, tl.col=&#39;black&#39;, tl.cex=.75) # chart.Correlation(histogram=TRUE, pch=19) # pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, font.main=4, pch=19) iris %&gt;% select(-Species) %&gt;% pairs( main=&quot;Edgar Anderson&#39;s Iris Data&quot;, font.main = 4, pch = 19, col = iris$Species) # pairs(iris[1:4], main=&quot;Edgar Anderson&#39;s Iris Data&quot;, font.main = 4, pch = 19, col = iris$Species) df_iris &lt;- iris %&gt;% select(-Species) # df_iris %&gt;% # correlation_table(&quot;&quot;) df_iris %&gt;% cor() %&gt;% # head(11) knitr::kable(caption = &quot;   &quot;) Table 4.1:     Sepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000   ?         Sepal.Length   Petal.Length, Petal.Width;                          Species       Petal.Length  Sepal.Width;           Species:           ,   ,            ?                          .            (PCA). # PCA resPCA &lt;- iris %&gt;% select(-Species) %&gt;% PCA(ncp = 8, graph = FALSE) #      eigenvalues &lt;- as.data.frame(resPCA$eig) cumVar &lt;- round(eigenvalues$`cumulative percentage of variance`[length(eigenvalues$eigenvalue[eigenvalues$eigenvalue &gt;= 0.9])], 2) knitr::kable( eigenvalues, caption = &quot;  (eigenvalues)     &quot; ) Table 4.2:   (eigenvalues)      eigenvalue percentage of variance cumulative percentage of variance comp 1 2.9184978 72.9624454 72.96245 comp 2 0.9140305 22.8507618 95.81321 comp 3 0.1467569 3.6689219 99.48213 comp 4 0.0207148 0.5178709 100.00000 # fviz_screeplot(resPCA, addlabels = TRUE, ncp=10)   ?   \\(p=\\) 2  ,   95.81 % .  ,                        :     ,     Y (. .).      ,    (. .  .). #       knitr::kable( resPCA$var$coord[ ,1:2], caption = &quot; &quot; ) Table 4.3:   Dim.1 Dim.2 Sepal.Length 0.8901688 0.3608299 Sepal.Width -0.4601427 0.8827163 Petal.Length 0.9915552 0.0234152 Petal.Width 0.9649790 0.0639998   ?         : Sepal.Length, Petal.Length, Petal.Width;    ,       ()              Sepal.Width             . # Biplot of individuals and variables fviz_pca_biplot(resPCA, geom = c(&quot;point&quot;), # label = &quot;none&quot;, # hide individual labels habillage = as.factor(iris$Species), # color by groups axes = c(1, 2), repel = TRUE, label = c(&quot;ind&quot;, &quot;ind.sup&quot;, &quot;quali&quot;, &quot;var&quot;, &quot;quanti.sup&quot;), select.var = list(name = c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, &quot;Petal.Length&quot;, &quot;Petal.Width&quot;)), # select.var = list(contrib = 8), # label = c(&quot;ind.sup&quot;), palette = c(&quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;, &quot;#00AFBB&quot;, &quot;#E7B800&quot;, &quot;#FC4E07&quot;), # alpha.var = c(&quot;contrib&quot;), # col.ind = c(&quot;contrib&quot;), # col.ind.sup = c(&quot;contrib&quot;), addEllipses = TRUE # Concentration ellipses ) + theme_minimal()  , ,      .          (petal length)      (petal width).      ,         .                     . 4.3.3       . References "],["--4.--.html", " 5   4.   5.1    ? 5.2   ", "  5   4.   :   ,                        R    dplyr, ggplot2. 5.1    ?                    R   IDE RStudio.      . 5.2         Data Mining    CRISP DM (wikipedia 2018a),      (Data Preparing)    (Modelling) (. 1). 5.2.1       . References "],["lab_5.html", " 6  2. .   5.    6.1    ? 6.2    6.3    ", "  6  2. .   5.    :   ,                        R    dplyr, ggplot2. 6.1    ?                    R   IDE RStudio. 6.2         Data Mining    CRISP DM (wikipedia 2018a),      (Data Preparing)    (Modelling) (. 1).                 .      : -   ; -   ; -  ; -  .      Data Mining   ,         :  ()   , , ,       . . 1.     Data Science- (Garrett Grolemund 2018)             . . 3    .        .      .         6. 6.2.1      ?                     .      : ,  ,   ,   \\(n\\)   \\(X_1, X_2, \\dots, X_n\\),   .    \\(Y\\),     ,    \\(X_1, X_2, \\dots, X_n\\).           \\(X\\)        \\(Y\\): \\[X=\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1,n} \\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\cdots \\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{n,n} \\\\ \\end{bmatrix},\\]  \\[Y=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}.\\]   ,       \\(X\\)  \\(Y\\)   ,      \\(y^*\\)  -     \\(x^*_1, x^*_2, \\dots, x^*_n\\)     (. 1):      ,    ,       . . 1.      (Viacheslav Oreshkov 2012)    ,         ,         ,    , , ,    .          . 6.2.2                     \\(Y\\)      \\(f(\\dots)\\)    : \\[E(Y|x_1, x_2, ..., x_n)=f( \\beta, x_1, x_2, ..., x_n) + \\epsilon,\\]   \\(\\epsilon\\)   ,            .    .               ()       .             ,     .   (Manuel Fernandez-Delgado 2014)              ,    : *   (Random Forest); *    (Support Vector Machines); *    (Artificial Neural Networks); *    (Boosting Ensembles).    , ,        ,  ,     .        ,   ,     (Explainable artificial intelligence,  )          .  ,    ,          ,          ,        ,  .          ()          . 6.2.3      .          : \\[Y=X\\beta+\\epsilon.\\]       : \\[\\hat{Y}=Xb,\\]  \\(b=\\begin{bmatrix} b_0 \\\\ b_1 \\\\ \\vdots \\\\ b_k \\end{bmatrix}\\).       \\(X\\)    \\(Y\\).    \\(\\epsilon\\): \\[\\epsilon=\\begin{bmatrix} \\epsilon_1\\\\ \\epsilon_2\\\\ \\vdots \\\\ \\epsilon_n\\\\ \\end{bmatrix},\\]  \\[\\epsilon=Y - \\hat{Y} = Y - Xb.\\] ,         \\(b\\)      : \\[U(b) = \\epsilon^T \\epsilon = (Y - Xb)^T (Y - Xb) \\rightarrow min. \\]     \\(b\\)     ,   : \\[X^TXb = X^TY,\\]     \\(b\\)   -    \\(\\beta\\): \\[b=(X^TX)^{-1}X^TY.\\] . ,    \\(X\\)     (),  \\(Y\\)     ().   \\(n=4\\)              \\(y=\\beta_0 + \\beta_1 + \\epsilon.\\)        \\(\\hat y = b_0 + b_1x\\),   -   \\(b \\sim \\beta\\).      : \\[X=\\begin{bmatrix} 1 &amp; 155 \\\\ 1 &amp; 198 \\\\ 1 &amp; 164 \\\\ 1 &amp; 178 \\\\ \\end{bmatrix}, Y=\\begin{bmatrix} 60 \\\\ 101 \\\\ 61 \\\\ 85 \\\\ \\end{bmatrix}.\\]  ,         \\(X\\)        .      -: \\[ b=(X^TX)^{-1}X^TY= \\Bigg( \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 155 &amp; 198 &amp; 164 &amp; 178 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 &amp; 155 \\\\ 1 &amp; 198 \\\\ 1 &amp; 164 \\\\ 1 &amp; 178 \\\\ \\end{bmatrix}\\Bigg )^{-1} \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 155 &amp; 198 &amp; 164 &amp; 178 \\\\ \\end{bmatrix} \\begin{bmatrix} 60 \\\\ 101 \\\\ 61 \\\\ 85 \\\\ \\end{bmatrix} = \\begin{bmatrix} -103.272\\\\ 1.036 \\end{bmatrix} \\]   Matrix        . suppressMessages(library(Matrix)) X &lt;- matrix(c(1, 155, 1, 198, 1, 164, 1, 178), nrow = 4, ncol = 2, byrow = TRUE) Y &lt;- c(60, 101, 61, 85) b &lt;- solve((t(X) %*% X)) %*% t(X) %*% Y b ## [,1] ## [1,] -103.271669 ## [2,] 1.036096   ,     R. plot(X[, 2], Y, main = &quot; &quot;, xlab = &quot;x, &quot;, ylab = &quot;y, &quot; ) abline(a = b[1], b = b[2], col = &quot;blue&quot;)   ,        .          .   R     ,         ,    ,     (.    ). 6.2.4           ,       ,   ,       (Random Forest).      (Random Forest) (Breiman 2001)                 .         ,     CART (Wikipedia 2020).           .    ,        :       \\(N\\),     \\(D\\).  L      .     \\(l\\)  \\(dl (dl&lt;L)\\)     \\(l\\).          \\(dl\\).     \\(l\\)   ,  \\(dl\\)   \\(D\\)   .           \\(L\\) .      N    :   \\(n = 1,..., N\\):   \\(X_n\\)   .   \\(b_n\\)   \\(X_n\\):      ,         ,     .  ,        \\(n_{min}\\),       .      \\(m\\)    \\(n\\) ,         .   \\(a(x) = \\frac{1}{N}\\sum_{i=1}^N b_i (x)\\).              .  ,      ,      .             :  \\(O(NK)\\)    ,  \\(K\\) -  .   -            ,       ,     . 6.3     :     Facebook    likes/shares/comments  ,    CRISP DM (wikipedia 2018a). 6.3.1        ,     \\(n=99\\)     ()          (. 1).    1.      ,      ( ) \\(\\),  posts      \\(x_1\\),  comments      \\(x_2\\),  likes     \\(x_3\\),  shares   \\(x_{123}=\\sum_\\limits{i=1}^3x_i\\),  all reactions   \\(y\\),  reach      Table 6.1:    posts comments likes shares all reactions reach 1 0 35 6 41 3847 2 1 34 1 36 1775 3 8 36 10 54 2074 4 3 69 19 91 2149 5 0 36 6 42 993 6 0 49 11 60 1406         , ,    ,                ,                 . 6.3.2    ,           . 6.3.3        (William of Ockham)            ,      (. . 1)      :     (   ) \\(y = f (x_1, x_2, x_3)\\),       \\(y\\)     \\(x_1, x_2, x_3\\).    ,        ,                   ().      .    ,        ,   ,            . ,     random forest.       (    , ,    (Slabchenko Olesia 2016))      random forest, ,  , ,    SVM-       .                    (  ):     (multiple regression)    (Ordinary Least Squares, OLS): \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\beta_3x_3)\\);      -        (Principal Component Regression);   (Simple regression)       (Squared-Y): \\(y = \\sqrt {\\beta_0 + \\beta_1x_2}\\);         (Squared-Y): \\(y=\\sqrt{\\beta_0+\\beta_1x_{123}}\\);    \\(y = f (x_1, x_2, x_3)\\)     (\\(random \\; forest\\)).   ,          ,          (.). data %&gt;% select(comments:shares, `all reactions`, reach) %&gt;% cor() %&gt;% knitr::kable(caption = &quot;   &quot;) Table 6.2:     comments likes shares all reactions reach comments 1.0000000 0.5388672 0.5359562 0.6134934 0.3788963 likes 0.5388672 1.0000000 0.8467100 0.9864025 0.6056677 shares 0.5359562 0.8467100 1.0000000 0.9137529 0.5321415 all reactions 0.6134934 0.9864025 0.9137529 1.0000000 0.6068925 reach 0.3788963 0.6056677 0.5321415 0.6068925 1.0000000 data %&gt;% select(comments:shares, reach) %&gt;% ggpairs()   ?  reach           : comments: 0.3788963 likes: 0.6056677 shares: 0.5321415            ,     : comments-likes: 0.5388672 comments-shares: 0.5359562 likes-shares: 0.84671        ,      .    (outliers),       (influential points),             .   ?   ,   comments,likes, shares    reach           . ( )     ,     \\(y=f(x_1, x_2, x_3)\\)  ,             . (   )        .           .   ,    , ,  -               ( ). (   )    -  ,     -                 . ( )   ,  ,         (. ).     (multiple regression)    (Ordinary Least Squares, OLS): \\(y=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\beta_3x_3)\\)          . ,     \\(40\\)  \\(94\\)     ,          . dataNotFilter &lt;- select(data, comments:shares, reach) lm.reach &lt;- lm(reach ~ ., data = dataNotFilter) summary(lm.reach) ## ## Call: ## lm(formula = reach ~ ., data = dataNotFilter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2918.0 -1211.7 -681.9 742.7 22858.1 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 799.215 543.557 1.470 0.14477 ## comments 33.522 48.010 0.698 0.48674 ## likes 30.974 9.146 3.386 0.00103 ** ## shares 8.243 26.163 0.315 0.75341 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2947 on 95 degrees of freedom ## Multiple R-squared: 0.3714, Adjusted R-squared: 0.3515 ## F-statistic: 18.71 on 3 and 95 DF, p-value: 1.288e-09 plot(lm.reach)        . dataFilter &lt;- data %&gt;% filter(posts %in% c(40, 94) != TRUE) %&gt;% select(comments:shares, reach) lm.reach &lt;- lm(reach ~ ., data = dataFilter) summary(lm.reach) ## ## Call: ## lm(formula = reach ~ ., data = dataFilter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2723.9 -864.7 -298.1 791.8 4406.8 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 513.996 255.442 2.012 0.0471 * ## comments 33.922 22.166 1.530 0.1293 ## likes 35.854 4.383 8.181 1.42e-12 *** ## shares -14.299 12.357 -1.157 0.2502 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1360 on 93 degrees of freedom ## Multiple R-squared: 0.71, Adjusted R-squared: 0.7006 ## F-statistic: 75.9 on 3 and 93 DF, p-value: &lt; 2.2e-16 plot(lm.reach)     :       \\(R^2=\\) 0.7100008.        71.0000847 \\(\\%\\),   ,        .  ,  likes  ,        ,            .    (\\(b_0\\))  ,         .        .     , ,  ,         ( Forward Stepwise Selection ). lmStep.reach &lt;- step(lm.reach, trace = 0) summary(lmStep.reach) ## ## Call: ## lm(formula = reach ~ likes, data = dataFilter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2412.1 -939.7 -296.1 964.5 4733.7 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 579.535 249.338 2.324 0.0222 * ## likes 33.759 2.267 14.893 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1369 on 95 degrees of freedom ## Multiple R-squared: 0.7001, Adjusted R-squared: 0.697 ## F-statistic: 221.8 on 1 and 95 DF, p-value: &lt; 2.2e-16 ,              \\(y=f(x_2)\\)     ,          \\(y=b_0+b_1x_1+b_2x_2+b_3x_3\\)  \\(y=b_0+b_1x_2\\): anova(lm.reach, lmStep.reach) ## Analysis of Variance Table ## ## Model 1: reach ~ comments + likes + shares ## Model 2: reach ~ likes ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 93 172115572 ## 2 95 177969257 -2 -5853685 1.5815 0.2112          (cross validation). lm.reach.cv &lt;- train(reach ~ ., data = dataFilter, method = &#39;lm&#39;, trainControl = trainControl(method = &quot;cv&quot;)) lmStep.reach.cv &lt;- train(reach ~ likes, data = dataFilter, method = &#39;lm&#39;, trainControl = trainControl(method = &quot;cv&quot;)) lm.reach.cv ## Linear Regression ## ## 97 samples ## 3 predictor ## ## No pre-processing ## Resampling: Bootstrapped (25 reps) ## Summary of sample sizes: 97, 97, 97, 97, 97, 97, ... ## Resampling results: ## ## RMSE Rsquared MAE ## 1441.364 0.6701918 1150.544 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE lmStep.reach.cv ## Linear Regression ## ## 97 samples ## 1 predictor ## ## No pre-processing ## Resampling: Bootstrapped (25 reps) ## Summary of sample sizes: 97, 97, 97, 97, 97, 97, ... ## Resampling results: ## ## RMSE Rsquared MAE ## 1403.034 0.6724215 1161.493 ## ## Tuning parameter &#39;intercept&#39; was held constant at a value of TRUE    ,        (RMSE),    ,     ( \\(2%\\))     . ,      ,  .    ,     ,      \\(y=b_1x_2\\): lm.MinusConst.reach &lt;- lm(reach ~ likes - 1, data = dataFilter) summary(lm.MinusConst.reach) ## ## Call: ## lm(formula = reach ~ likes - 1, data = dataFilter) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2342.9 -734.5 -194.9 1198.5 5037.6 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## likes 38.133 1.292 29.51 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1400 on 96 degrees of freedom ## Multiple R-squared: 0.9007, Adjusted R-squared: 0.8997 ## F-statistic: 871.1 on 1 and 96 DF, p-value: &lt; 2.2e-16 plot(lm.MinusConst.reach) ggplot(dataFilter, aes(x = likes - 1, y = reach, colour = comments)) + labs(title = &quot;     &quot;, subtitle = &quot;   95%  &quot;, caption = &quot; .    &quot;, x = &quot; &quot;, y = &quot; , . .&quot;) + geom_point() + stat_smooth(method=lm, se = TRUE, fullrange = TRUE) ## `geom_smooth()` using formula &#39;y ~ x&#39;     ,          (11, 24). dataFilterThreeSigma &lt;- data %&gt;% filter(posts %in% c(11, 24, 40, 94) != TRUE) %&gt;% #   ,     select(comments:shares, reach)  . lm.MinusConstThreeSigma.reach &lt;- lm(reach ~ likes - 1, data = dataFilterThreeSigma) summary(lm.MinusConstThreeSigma.reach) ## ## Call: ## lm(formula = reach ~ likes - 1, data = dataFilterThreeSigma) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2278.4 -700.1 -191.1 1124.8 2725.0 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## likes 37.679 1.166 32.31 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1259 on 94 degrees of freedom ## Multiple R-squared: 0.9174, Adjusted R-squared: 0.9165 ## F-statistic: 1044 on 1 and 94 DF, p-value: &lt; 2.2e-16 # plot(lm.MinusConst.reach)  . ggplot(dataFilterThreeSigma, aes(x = likes - 1, y = reach, colour = comments)) + labs(title = &quot;     &quot;, subtitle = &quot;   95%  &quot;, caption = &quot; .    &quot;, x = &quot; &quot;, y = &quot; , . .&quot;) + geom_point() + stat_smooth(method=lm, se = TRUE, fullrange = TRUE) ## `geom_smooth()` using formula &#39;y ~ x&#39;       ?  : \\(y=\\) 37.6789647 \\(\\cdot x_2\\)       :   ,         ,    37   .       \\(R^2=\\) 0.9174168.        91.7416806 \\(\\%\\),   ,      .             \\(95\\%\\)-      .   : likesNumber &lt;- data.frame(likes=c(200, 250, 255)) #   likes     reaches pre &lt;- predict(lm.MinusConstThreeSigma.reach, likesNumber, interval=&quot;confidence&quot;) knitr::kable(cbind(likesNumber, pre), caption = &quot;     &quot;) Table 6.3:       likes fit lwr upr 200 7535.793 7072.770 7998.816 250 9419.741 8840.962 9998.520 255 9608.136 9017.782 10198.490 ,    \\(200\\) ,      ,  \\(95\\%\\) ,      7535,   ,  7072,   ,  7998.           :   (Simple regression)       (Squared-Y): \\(y=\\sqrt{\\beta_0+\\beta_1x_2}\\);         (Squared-Y): \\(y=\\sqrt{\\beta_0+\\beta_1x_{123}}\\);   ,              likes,         .        (\\(random\\; forest\\))         100  .           ,   ,        .                 likes.        (. )          \\(95\\%\\) ( \\(0,95\\))  .     comments  shares         ,    .           .    ,            , ,  ,        ().         .                     .     -            .               comments  shares         ,       (     ):    : \\(y=b_1x_1+b_2x_2+b_3x_3\\)           : \\(y=b_1x_1+b_2x_2+b_3x_3+b_{12}x_1x_2+b_{13}x_1x_3+b_{23}x_2\\)       ,   .   : lm.reach &lt;- lm(reach ~ comments + likes + shares - 1, data = dataFilterThreeSigma) summary(lm.reach) ## ## Call: ## lm(formula = reach ~ comments + likes + shares - 1, data = dataFilterThreeSigma) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2659.5 -709.1 -156.7 1012.0 2952.8 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## comments 22.16 20.61 1.075 0.2851 ## likes 41.43 3.18 13.028 &lt;2e-16 *** ## shares -19.58 11.01 -1.778 0.0787 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1248 on 92 degrees of freedom ## Multiple R-squared: 0.9207, Adjusted R-squared: 0.9181 ## F-statistic: 355.9 on 3 and 92 DF, p-value: &lt; 2.2e-16 # plot(lm.reach)       ?   Coefficients:     \\(Pr(&gt;|t|)\\)  ,  \\(0,05\\),  ,   ,               \\(\\alpha=0,05\\). ,    : \\(y=\\) 22.1566353 \\(\\cdot x_1+\\) 41.4335882 \\(\\cdot x_2+\\) -19.5814839 \\(\\cdot x_3\\),   (   !): \\(y=\\) 41.4335882 \\(\\cdot x_2\\).              .               ,   ,    .    : Multiple R-squared,        .    : \\(R^2=\\) 0.9206595.        92.0659531 \\(\\%\\),   ,      .   . lm.general.reach &lt;- lm(reach ~ comments + likes + shares + comments*likes + comments*shares + likes*shares - 1, data = dataFilterThreeSigma) summary(lm.general.reach) ## ## Call: ## lm(formula = reach ~ comments + likes + shares + comments * likes + ## comments * shares + likes * shares - 1, data = dataFilterThreeSigma) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2489.7 -809.4 -117.0 849.7 2788.9 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## comments 64.65151 39.07336 1.655 0.102 ## likes 43.79321 5.09790 8.590 2.64e-13 *** ## shares -25.09527 20.59867 -1.218 0.226 ## comments:likes -0.66600 0.36319 -1.834 0.070 . ## comments:shares 0.68694 1.53120 0.449 0.655 ## likes:shares 0.04449 0.13098 0.340 0.735 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1225 on 89 degrees of freedom ## Multiple R-squared: 0.926, Adjusted R-squared: 0.921 ## F-statistic: 185.5 on 6 and 89 DF, p-value: &lt; 2.2e-16 # plot(lm.reach)       ?   Coefficients:     \\(Pr(&gt;|t|)\\)  ,  \\(0,05\\),  ,   ,              \\(\\alpha=0,05\\). ,    : \\(y=\\) 64.6515059 \\(\\cdot x_1+\\) 43.7932086 \\(\\cdot x_2+\\) -25.0952651 \\(\\cdot x_3+\\) -0.6659987 \\(\\cdot x_1 x_2+\\) 0.6869435 \\(\\cdot x_1 x_3+\\) 0.0444853 \\(\\cdot x_2 x_3\\),   (   !): \\(y=\\) 43.7932086 \\(\\cdot x_2\\)              .               ,   ,    .    : Multiple R-squared,        .    : \\(R^2=\\) 0.9259555.        92.5955527 \\(\\%\\),   ,      .    ,                 likes.    ,     ,   .   random forest. {#rf}    ,      .                     ,      - ,     . head(dataFilterThreeSigma) ## comments likes shares reach ## 1 0 35 6 3847 ## 2 1 34 1 1775 ## 3 8 36 10 2074 ## 4 3 69 19 2149 ## 5 0 36 6 993 ## 6 0 49 11 1406 # 80%     , 20%   split &lt;- sample(2, nrow(dataFilterThreeSigma), replace=TRUE, prob=c(0.8, 0.2)) train &lt;- dataFilterThreeSigma[split==1,] test &lt;- dataFilterThreeSigma[split==2,] #   # rf &lt;- randomForest(reach ~ ., data = train) rf &lt;- randomForest(reach ~ ., data = train, scale=FALSE, ntree=500) rf ## ## Call: ## randomForest(formula = reach ~ ., data = train, scale = FALSE, ntree = 500) ## Type of random forest: regression ## Number of trees: 500 ## No. of variables tried at each split: 1 ## ## Mean of squared residuals: 2427730 ## % Var explained: 59.4 #      predictions &lt;- predict(rf, test) #   print(sqrt(sum((as.vector(predictions - test$reach))^2))/length(predictions)) ## [1] 316.7715 #    plot(rf) #    importance(rf) ## IncNodePurity ## comments 95473346 ## likes 178721544 ## shares 113786972    ,      \\(300\\)     .       ,  likes     . 6.3.4       . References "],["lab_6.html", " 7   6.    7.1    ? 7.2    7.3    ", "  7   6.    :   ,       , e                   R            caret. 7.1    ?              R   caret   IDE RStudio.  /   /  . 7.2         Data Mining    CRISP DM (wikipedia 2018a),      (Data Preparing)    (Modelling) (. 1).                 .      :   ;   ;  ;  .      Data Mining   ,         :  ()   , , ,       . . 1.     Data Science- (Garrett Grolemund 2018)             . . 3    .        .       ,         (.  . . 5. 7.2.1     ?                     .      : ,  ,   ,   \\(n\\)   \\(X_1, X_2, \\dots, X_n\\),   .    \\(Y\\),     ,    \\(X_1, X_2, \\dots, X_n\\).           \\(X\\)        \\(Y\\): \\[X=\\begin{bmatrix} x_{11} &amp; x_{12} &amp; \\cdots &amp; x_{1,n} \\\\ x_{21} &amp; x_{22} &amp; \\cdots &amp; x_{2,n} \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\cdots \\\\ x_{n1} &amp; x_{n2} &amp; \\cdots &amp; x_{n,n} \\\\ \\end{bmatrix},\\]  \\[Y=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}.\\]   ,       \\(X\\)  \\(Y\\)   ,      \\(y^*\\)  -     \\(x^*_1, x^*_2, \\dots, x^*_n\\)     (. 1):      ,    ,       . . 1.      (Viacheslav Oreshkov 2012)    ,         ,         ,    , , ,    .           . 7.2.2         . ,       \\(X \\times Y\\)        \\(\\mathrm{P}\\).      \\(X^m = \\big\\{ (x_1, y_1), (x_2, y_2), ..., (x_m, y_m) \\big\\}\\),      \\(\\mathrm{P}\\).    \\(a\\): \\(X \\rightarrow Y\\),     \\(x \\in X\\).              (  ,  ),        ( ,  ,  ).   ,   (Manuel Fernandez-Delgado 2014)              ,    :   (Random Forest);    (Support Vector Machines);    (Artificial Neural Networks);    (Boosting Ensembles). ,    ,     (Explainable artificial intelligence), ,     .             caret (.   CRAN). 7.2.3  caret          ,    ,          .  , ,         ,     ,        .                      .        ,        ,   R      (, Weka).  caret (Max Kuhn 2021)      (Shitikov V. K. 2017):        R            ;   ,             ,    ,    ;     ,   ;      .      caret (  Classification and Regression Training),           R,     .    caret       ((M. Kuhn 2008), (M. Kuhn 2003), (Kuhn M. 2013), (M. Kuhn 2013)).   ,                   .     ,      .  ,   ,   ,       caret        /           (Khramov 2017). 7.3     (-.  ) .     iris:   ;     ;      . 7.3.1   library(caret) #   data &lt;- iris #       . set.seed(1234) trainIndex &lt;- createDataPartition(1:nrow(data), times = 1, p = .8) # (1) trainSet &lt;- data[trainIndex$Resample1,] testSet &lt;- data[-trainIndex$Resample1,] #   fitCtrl &lt;- trainControl(method = &quot;repeatedcv&quot;, # - number = 10, #    10  repeats = 5 #   ) #        model &lt;- train(trainSet[,-5],trainSet[,5], method = &#39;lda&#39;, trControl = fitCtrl ) #  ,    : # str(model) fit &lt;- model$finalModel # str(fit) 7.3.2           list (),     ,        ,          .      .       serialize        . #      fit_char &lt;- rawToChar(serialize(fit, NULL, TRUE)) nchar(fit_char) #   ? ## [1] 1830          .    SQLite     . library(DBI) #   . # db &lt;- dbConnect(RSQLite::SQLite(), dbname=&quot;models.sqlite&quot;) #      . # dbGetQuery(db, &quot;DROP TABLE IF EXISTS models&quot;) #    : # &#39;id&#39;, # &#39;model&#39; -  ,   &#39;VARCHAR(2000)&#39;. # dbGetQuery(db, &#39;CREATE TABLE IF NOT EXISTS models # (id INT PRIMARY KEY, # model VARCHAR(2000))&#39; # ) #  data.frame    . df &lt;- data.frame(id = 1, mdl = fit_char) #     . # dbGetPreparedQuery(db, &#39;INSERT INTO models (model) values (:mdl)&#39;, # bind.data = df) # dbDisConnect(db) 7.3.3                  .         R (model2).      unserialize. #     . db &lt;- dbConnect(RSQLite::SQLite(), dbname=&quot;models.sqlite&quot;) df2 &lt;- dbGetQuery(db, &quot;SELECT * FROM models&quot;) #     R. model2 &lt;- unserialize(charToRaw(df2$model)) class(model2) ## [1] &quot;lda&quot; #      . prediction &lt;- predict(model2, newdata = testSet[,-5]) #   . confusionMatrix(prediction$class, testSet[,5]) ## Confusion Matrix and Statistics ## ## Reference ## Prediction setosa versicolor virginica ## setosa 12 0 0 ## versicolor 0 7 0 ## virginica 0 0 9 ## ## Overall Statistics ## ## Accuracy : 1 ## 95% CI : (0.8766, 1) ## No Information Rate : 0.4286 ## P-Value [Acc &gt; NIR] : 4.973e-11 ## ## Kappa : 1 ## ## Mcnemar&#39;s Test P-Value : NA ## ## Statistics by Class: ## ## Class: setosa Class: versicolor Class: virginica ## Sensitivity 1.0000 1.00 1.0000 ## Specificity 1.0000 1.00 1.0000 ## Pos Pred Value 1.0000 1.00 1.0000 ## Neg Pred Value 1.0000 1.00 1.0000 ## Prevalence 0.4286 0.25 0.3214 ## Detection Rate 0.4286 0.25 0.3214 ## Detection Prevalence 0.4286 0.25 0.3214 ## Balanced Accuracy 1.0000 1.00 1.0000 #  &#39;  . dbDisconnect(db) #      . # dbGetQuery(db, &quot;DROP TABLE IF EXISTS models&quot;) 7.3.4       . References "],["--7.---.html", " 8   7.    8.1    ? 8.2    8.3    ", "  8   7.    :   ,                   R     arules (Hahsler et al. 2022)  arulesViz (Hahsler 2021). 8.1    ?        R   arules   IDE RStudio.          arulesViz. 8.2         Data Mining    CRISP DM (wikipedia 2018a),      (Data Preparing)    (Modelling) (. 1).                 .      :   ;   ;  ;  .      Data Mining   ,         :  ()   , , ,       ( ). . 1.     Data Science-             . . 3    .        .        . . 5  . . 6 .          . 8.2.1       ?         Data Mining.       ,        .       .           .       ,     .            ,    ,   ,       ,      . .       ,     . . ,   ,    ,     ,   : \\(\\{, \\}; \\{, \\}\\). ,   ,      , ,  ,      .   ,     ,           ,     .           . ,        ,       .           ,        (, ).   , ,      ,     .        ,    .      ,        ,       (Barsegjan 2007). 8.2.2           (Barsegjan 2007).    ,     (itemsets),  : \\[I = \\{ i_1, i_2,..., i_j,...,i_n \\},\\]  \\(i_j\\)  ,    ,   ; \\(n\\)    .   , ,    ,   -. Table 8.1: -  .  0  30 1  12 2  10 3  4 4  14 5  15     : \\[I = \\{, , , , ,  \\}.\\]     \\(I\\),       ,  .      \\(I\\): \\[T = \\{i_j | i_j \\in I \\}. \\]       ,             .      ,  ,  . ,    ,     : \\[ T_1 = \\{ , ,  \\}; \\\\ T_2 = \\{, ,  \\}. \\]  ,      ,   : \\[D = \\{ T_1, ..., T_2,..., T_r,..., T_m \\},\\]  \\(m\\)      . ,     : \\[D = \\{ \\{, ,  \\}, \\{, ,  \\}, \\\\ \\{, , , ,  \\}, \\\\ \\{, ,  \\} \\}.\\]    Data Mining  D      . 2. Table 8.2: - . . .  0 1  12 0 3  4 0 4  14 1 2  10 1 3  4 1 5  15 2 5  15 2 2  10 2 1  12 2 2  10 2 3  4 3 2  10 3 5  15 3 2  10  ,     \\(j_i\\),    : \\[D_{i_j} = \\{ T_r | i_j \\in T_r; j = 1..n; r = 1..m \\} \\subseteq D.\\]     ,    ,   : \\[D = \\{ \\{, , \\},\\\\ \\{, ,  \\}, \\\\ \\{ , , , ,  \\}\\}.\\]     (itemset)    : \\[F = \\{ i_j | i_j \\in I; j = 1..n \\}.\\] , \\[F = \\{ ,  \\}.\\] ,    \\(k\\) ,  \\(k\\)-  (    2- ).  ,     \\(F\\),    : \\[D_F = \\{ T_r | F \\subseteq T_r; r = 1..m \\} \\subseteq D.\\]   : \\[D \\{ ,  \\} = \\{ \\{, ,  \\}, \\{ , , , ,  \\} \\}.\\]   ,     \\(F\\),       (support)  \\(F\\)   \\(S(F)\\): \\[S(F) = \\frac{|D_F|}{D}.\\]   \\(\\{, \\}\\)    \\(0,5\\),         (  \\(1\\)  \\(2\\)),    \\(4\\).            \\(S_{min}\\).    (large itemset),        ,  : \\[S(F) &gt; S_{min}.\\]  ,          : \\[L = \\{ F | S(F) &gt; S_{min} \\}.\\]       \\(S_{min} = 0,5\\)  : \\[\\{\\} \\; S_{min} = 0,5; \\\\ \\{,  \\} \\; S_{min} = 0,5; \\\\ \\{\\} \\; S_{min} = 0,75; \\\\ \\{, \\} \\; S_{min} = 0,5;\\\\ \\{, , \\} \\; S_{min} = 0,5; \\\\ \\{, \\} \\; S_{min} = 0,75;\\\\ \\{\\} \\; S_{min} = 0,75; \\\\ \\{, \\} \\; S_{min} = 0,5; \\\\ \\{\\} \\; S_{min} = 0,75.\\] ,     ,      .           :     ;        .     :  ()  ()        (   ),      \\(I\\),    () ,     . ,  : \\[ \\; (, ) \\;  \\; ()\\] ,       ,     .   ,          \\(I\\): \\[ \\; X \\;  \\; Y,\\]  \\(X \\in I, Y \\in I, X \\cup Y = \\phi.\\)       ()   \\(X \\Rightarrow Y\\),  \\(X \\in I, Y \\in I, X \\cup Y = \\phi.\\) 8.2.3                   .     .    :      ,    ,    .        ,   ;         ,   .  ,    ,     - ,         ,    .         ,     ;     ,     .          ,    .         ,         .      .            , , ,    Data Mining.               .        .       .    .        .     ,           Hahsler, Gruen, and Hornik (2005).  (support)    \\(X \\cap Y\\); ,           \\(F\\),   \\(X\\)  \\(Y\\): \\[ S(X \\Rightarrow Y) = P(X \\cap Y) = S_F = \\frac{|D_{F=X \\cup Y}|}{|D|}. \\] . \\[S_{ \\; (, \\; ) \\;  \\; ()} = S_{(, \\; , \\; )} = \\frac{2}{4}.\\]  (confidence)     \\(Y\\)  ,     \\(X\\);    ,       \\(X\\)      \\(Y\\).     ,    \\(X\\)  \\(Y\\),   ,    \\(X\\): \\[ C(X \\Rightarrow Y) = P(Y|X) = \\frac{P(X \\cap Y)}{P(X)} = \\frac{|D_{F=X \\cup Y}|}{|D_X|} = \\frac{S_{X \\cup Y}}{S_Y}. \\] . \\[_{ \\; (, \\;  \\; ()} = \\frac{2}{3}.\\]   ,   .       .    .  (lift)     \\(Y|X\\)   \\(Y\\),   ,      : \\[ L(X \\Rightarrow Y) = \\frac{P(Y|X)}{P(Y)} = \\frac{P(X \\cap Y)}{P(X)P(Y)} = \\frac{|D_{F=X \\cup Y}|}{|D_X| |D_Y|} = \\frac{S_{X \\cup Y}}{S_Y S_X}. \\] ,     ,    ,        \\(Y\\),   . . \\[L_{ \\; (, \\;  \\; ()} = \\frac{0,5}{0,5 \\cdot 0,5} = 2.\\]          Apriori,        1994 .      (Barsegjan 2007). ( ,    ) 8.2.4  arules  arulesViz (under construction) 8.3     .     titanic: #         df &lt;- as.data.frame(Titanic) head(df) ## Class Sex Age Survived Freq ## 1 1st Male Child No 0 ## 2 2nd Male Child No 0 ## 3 3rd Male Child No 35 ## 4 Crew Male Child No 0 ## 5 1st Female Child No 0 ## 6 2nd Female Child No 0 titanic.raw &lt;- NULL for(i in 1:4) { titanic.raw &lt;- cbind(titanic.raw, rep(as.character(df[,i]), # ????????? ??? ?????? df$Freq)) # ??????? ??? } titanic.raw &lt;- as.data.frame(titanic.raw) names(titanic.raw) &lt;- names(df)[1:4] dim(titanic.raw) ## [1] 2201 4 head(titanic.raw) ## Class Sex Age Survived ## 1 3rd Male Child No ## 2 3rd Male Child No ## 3 3rd Male Child No ## 4 3rd Male Child No ## 5 3rd Male Child No ## 6 3rd Male Child No    apriori()   arules.       : minimum support: supp=0.1 minimum condence: conf=0.8 maximum length of rules: maxlen=10        apriori       ,      . library(arules) ## ## Attaching package: &#39;arules&#39; ## The following object is masked from &#39;package:car&#39;: ## ## recode ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following objects are masked from &#39;package:base&#39;: ## ## abbreviate, write library(arulesViz) library(magrittr) rules.all &lt;- titanic.raw %&gt;% apriori() ## run the APRIORI algorithm ## Warning: Column(s) 1, 2, 3, 4 not logical or factor. Applying default ## discretization (see &#39;? discretizeDF&#39;). ## Apriori ## ## Parameter specification: ## confidence minval smax arem aval originalSupport maxtime support minlen ## 0.8 0.1 1 none FALSE TRUE 5 0.1 1 ## maxlen target ext ## 10 rules TRUE ## ## Algorithmic control: ## filter tree heap memopt load sort verbose ## 0.1 TRUE TRUE FALSE TRUE 2 TRUE ## ## Absolute minimum support count: 220 ## ## set item appearances ...[0 item(s)] done [0.00s]. ## set transactions ...[10 item(s), 2201 transaction(s)] done [0.00s]. ## sorting and recoding items ... [9 item(s)] done [0.00s]. ## creating transaction tree ... done [0.00s]. ## checking subsets of size 1 2 3 4 done [0.00s]. ## writing ... [27 rule(s)] done [0.00s]. ## creating S4 object ... done [0.00s]. rules.all %&gt;% length() ## number of rules discovered ## [1] 27 ## [1] 27 rules.all %&gt;% # as.data.frame() %&gt;% inspect() %&gt;% ## print all rules knitr::kable() ## lhs rhs support confidence ## [1] {} =&gt; {Age=Adult} 0.9504771 0.9504771 ## [2] {Class=2nd} =&gt; {Age=Adult} 0.1185825 0.9157895 ## [3] {Class=1st} =&gt; {Age=Adult} 0.1449341 0.9815385 ## [4] {Sex=Female} =&gt; {Age=Adult} 0.1930940 0.9042553 ## [5] {Class=3rd} =&gt; {Age=Adult} 0.2848705 0.8881020 ## [6] {Survived=Yes} =&gt; {Age=Adult} 0.2971377 0.9198312 ## [7] {Class=Crew} =&gt; {Sex=Male} 0.3916402 0.9740113 ## [8] {Class=Crew} =&gt; {Age=Adult} 0.4020900 1.0000000 ## [9] {Survived=No} =&gt; {Sex=Male} 0.6197183 0.9154362 ## [10] {Survived=No} =&gt; {Age=Adult} 0.6533394 0.9651007 ## [11] {Sex=Male} =&gt; {Age=Adult} 0.7573830 0.9630272 ## [12] {Sex=Female, Survived=Yes} =&gt; {Age=Adult} 0.1435711 0.9186047 ## [13] {Class=3rd, Sex=Male} =&gt; {Survived=No} 0.1917310 0.8274510 ## [14] {Class=3rd, Survived=No} =&gt; {Age=Adult} 0.2162653 0.9015152 ## [15] {Class=3rd, Sex=Male} =&gt; {Age=Adult} 0.2099046 0.9058824 ## [16] {Sex=Male, Survived=Yes} =&gt; {Age=Adult} 0.1535666 0.9209809 ## [17] {Class=Crew, Survived=No} =&gt; {Sex=Male} 0.3044071 0.9955423 ## [18] {Class=Crew, Survived=No} =&gt; {Age=Adult} 0.3057701 1.0000000 ## [19] {Class=Crew, Sex=Male} =&gt; {Age=Adult} 0.3916402 1.0000000 ## [20] {Class=Crew, Age=Adult} =&gt; {Sex=Male} 0.3916402 0.9740113 ## [21] {Sex=Male, Survived=No} =&gt; {Age=Adult} 0.6038164 0.9743402 ## [22] {Age=Adult, Survived=No} =&gt; {Sex=Male} 0.6038164 0.9242003 ## [23] {Class=3rd, Sex=Male, Survived=No} =&gt; {Age=Adult} 0.1758292 0.9170616 ## [24] {Class=3rd, Age=Adult, Survived=No} =&gt; {Sex=Male} 0.1758292 0.8130252 ## [25] {Class=3rd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.1758292 0.8376623 ## [26] {Class=Crew, Sex=Male, Survived=No} =&gt; {Age=Adult} 0.3044071 1.0000000 ## [27] {Class=Crew, Age=Adult, Survived=No} =&gt; {Sex=Male} 0.3044071 0.9955423 ## coverage lift count ## [1] 1.0000000 1.0000000 2092 ## [2] 0.1294866 0.9635051 261 ## [3] 0.1476602 1.0326798 319 ## [4] 0.2135393 0.9513700 425 ## [5] 0.3207633 0.9343750 627 ## [6] 0.3230350 0.9677574 654 ## [7] 0.4020900 1.2384742 862 ## [8] 0.4020900 1.0521033 885 ## [9] 0.6769650 1.1639949 1364 ## [10] 0.6769650 1.0153856 1438 ## [11] 0.7864607 1.0132040 1667 ## [12] 0.1562926 0.9664669 316 ## [13] 0.2317129 1.2222950 422 ## [14] 0.2398910 0.9484870 476 ## [15] 0.2317129 0.9530818 462 ## [16] 0.1667424 0.9689670 338 ## [17] 0.3057701 1.2658514 670 ## [18] 0.3057701 1.0521033 673 ## [19] 0.3916402 1.0521033 862 ## [20] 0.4020900 1.2384742 862 ## [21] 0.6197183 1.0251065 1329 ## [22] 0.6533394 1.1751385 1329 ## [23] 0.1917310 0.9648435 387 ## [24] 0.2162653 1.0337773 387 ## [25] 0.2099046 1.2373791 387 ## [26] 0.3044071 1.0521033 670 ## [27] 0.3057701 1.2658514 670 lhs rhs support confidence coverage lift count [1] {} =&gt; {Age=Adult} 0.9504771 0.9504771 1.0000000 1.0000000 2092 [2] {Class=2nd} =&gt; {Age=Adult} 0.1185825 0.9157895 0.1294866 0.9635051 261 [3] {Class=1st} =&gt; {Age=Adult} 0.1449341 0.9815385 0.1476602 1.0326798 319 [4] {Sex=Female} =&gt; {Age=Adult} 0.1930940 0.9042553 0.2135393 0.9513700 425 [5] {Class=3rd} =&gt; {Age=Adult} 0.2848705 0.8881020 0.3207633 0.9343750 627 [6] {Survived=Yes} =&gt; {Age=Adult} 0.2971377 0.9198312 0.3230350 0.9677574 654 [7] {Class=Crew} =&gt; {Sex=Male} 0.3916402 0.9740113 0.4020900 1.2384742 862 [8] {Class=Crew} =&gt; {Age=Adult} 0.4020900 1.0000000 0.4020900 1.0521033 885 [9] {Survived=No} =&gt; {Sex=Male} 0.6197183 0.9154362 0.6769650 1.1639949 1364 [10] {Survived=No} =&gt; {Age=Adult} 0.6533394 0.9651007 0.6769650 1.0153856 1438 [11] {Sex=Male} =&gt; {Age=Adult} 0.7573830 0.9630272 0.7864607 1.0132040 1667 [12] {Sex=Female, Survived=Yes} =&gt; {Age=Adult} 0.1435711 0.9186047 0.1562926 0.9664669 316 [13] {Class=3rd, Sex=Male} =&gt; {Survived=No} 0.1917310 0.8274510 0.2317129 1.2222950 422 [14] {Class=3rd, Survived=No} =&gt; {Age=Adult} 0.2162653 0.9015152 0.2398910 0.9484870 476 [15] {Class=3rd, Sex=Male} =&gt; {Age=Adult} 0.2099046 0.9058824 0.2317129 0.9530818 462 [16] {Sex=Male, Survived=Yes} =&gt; {Age=Adult} 0.1535666 0.9209809 0.1667424 0.9689670 338 [17] {Class=Crew, Survived=No} =&gt; {Sex=Male} 0.3044071 0.9955423 0.3057701 1.2658514 670 [18] {Class=Crew, Survived=No} =&gt; {Age=Adult} 0.3057701 1.0000000 0.3057701 1.0521033 673 [19] {Class=Crew, Sex=Male} =&gt; {Age=Adult} 0.3916402 1.0000000 0.3916402 1.0521033 862 [20] {Class=Crew, Age=Adult} =&gt; {Sex=Male} 0.3916402 0.9740113 0.4020900 1.2384742 862 [21] {Sex=Male, Survived=No} =&gt; {Age=Adult} 0.6038164 0.9743402 0.6197183 1.0251065 1329 [22] {Age=Adult, Survived=No} =&gt; {Sex=Male} 0.6038164 0.9242003 0.6533394 1.1751385 1329 [23] {Class=3rd, Sex=Male, Survived=No} =&gt; {Age=Adult} 0.1758292 0.9170616 0.1917310 0.9648435 387 [24] {Class=3rd, Age=Adult, Survived=No} =&gt; {Sex=Male} 0.1758292 0.8130252 0.2162653 1.0337773 387 [25] {Class=3rd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.1758292 0.8376623 0.2099046 1.2373791 387 [26] {Class=Crew, Sex=Male, Survived=No} =&gt; {Age=Adult} 0.3044071 1.0000000 0.3044071 1.0521033 670 [27] {Class=Crew, Age=Adult, Survived=No} =&gt; {Sex=Male} 0.3044071 0.9955423 0.3057701 1.2658514 670     ,               ,         .             . rules.surv &lt;- titanic.raw %&gt;% apriori( control = list(verbose=F), parameter = list(minlen=2, supp=0.005, conf=0.8), appearance = list(rhs=c(&quot;Survived=No&quot;, &quot;Survived=Yes&quot;), default=&quot;lhs&quot;)) ## Warning: Column(s) 1, 2, 3, 4 not logical or factor. Applying default ## discretization (see &#39;? discretizeDF&#39;). ## keep three decimal places quality(rules.surv) &lt;- rules.surv %&gt;% quality() %&gt;% round(digits=3) ## sort rules by lift rules.surv.sorted &lt;- rules.surv %&gt;% sort(by=&quot;lift&quot;) rules.surv.sorted %&gt;% inspect() ## print rules ## lhs rhs support confidence ## [1] {Class=2nd, Age=Child} =&gt; {Survived=Yes} 0.011 1.000 ## [2] {Class=2nd, Sex=Female, Age=Child} =&gt; {Survived=Yes} 0.006 1.000 ## [3] {Class=1st, Sex=Female} =&gt; {Survived=Yes} 0.064 0.972 ## [4] {Class=1st, Sex=Female, Age=Adult} =&gt; {Survived=Yes} 0.064 0.972 ## [5] {Class=2nd, Sex=Female} =&gt; {Survived=Yes} 0.042 0.877 ## [6] {Class=Crew, Sex=Female} =&gt; {Survived=Yes} 0.009 0.870 ## [7] {Class=Crew, Sex=Female, Age=Adult} =&gt; {Survived=Yes} 0.009 0.870 ## [8] {Class=2nd, Sex=Female, Age=Adult} =&gt; {Survived=Yes} 0.036 0.860 ## [9] {Class=2nd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.070 0.917 ## [10] {Class=2nd, Sex=Male} =&gt; {Survived=No} 0.070 0.860 ## [11] {Class=3rd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.176 0.838 ## [12] {Class=3rd, Sex=Male} =&gt; {Survived=No} 0.192 0.827 ## coverage lift count ## [1] 0.011 3.096 24 ## [2] 0.006 3.096 13 ## [3] 0.066 3.010 141 ## [4] 0.065 3.010 140 ## [5] 0.048 2.716 93 ## [6] 0.010 2.692 20 ## [7] 0.010 2.692 20 ## [8] 0.042 2.663 80 ## [9] 0.076 1.354 154 ## [10] 0.081 1.271 154 ## [11] 0.210 1.237 387 ## [12] 0.232 1.222 422          . subset.matrix &lt;- is.subset(rules.surv.sorted, rules.surv.sorted) subset.matrix[lower.tri(subset.matrix, diag = T)] &lt;- F redundant &lt;- colSums(subset.matrix) &gt;= 1 ## which rules are redundant redundant %&gt;% which() ## {Class=2nd,Sex=Female,Age=Child,Survived=Yes} ## 2 ## {Class=1st,Sex=Female,Age=Adult,Survived=Yes} ## 4 ## {Class=Crew,Sex=Female,Age=Adult,Survived=Yes} ## 7 ## {Class=2nd,Sex=Female,Age=Adult,Survived=Yes} ## 8 ## remove redundant rules rules.surv.pruned &lt;- rules.surv.sorted[!redundant] rules.surv.pruned %&gt;% inspect() ## print rules ## lhs rhs support confidence ## [1] {Class=2nd, Age=Child} =&gt; {Survived=Yes} 0.011 1.000 ## [2] {Class=1st, Sex=Female} =&gt; {Survived=Yes} 0.064 0.972 ## [3] {Class=2nd, Sex=Female} =&gt; {Survived=Yes} 0.042 0.877 ## [4] {Class=Crew, Sex=Female} =&gt; {Survived=Yes} 0.009 0.870 ## [5] {Class=2nd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.070 0.917 ## [6] {Class=2nd, Sex=Male} =&gt; {Survived=No} 0.070 0.860 ## [7] {Class=3rd, Sex=Male, Age=Adult} =&gt; {Survived=No} 0.176 0.838 ## [8] {Class=3rd, Sex=Male} =&gt; {Survived=No} 0.192 0.827 ## coverage lift count ## [1] 0.011 3.096 24 ## [2] 0.066 3.010 141 ## [3] 0.048 2.716 93 ## [4] 0.010 2.692 20 ## [5] 0.076 1.354 154 ## [6] 0.081 1.271 154 ## [7] 0.210 1.237 387 ## [8] 0.232 1.222 422             tidy.    .  . 8.3.1       . References "],["lab_8.html", " 9    8.  ARIMA-        (short version) 9.1    ? 9.2 ts- 9.3   9.4    9.5     ARIMA- 9.6    ", "  9    8.  ARIMA-        (short version) :  ARIMA-         R. 9.1    ?     ().              .      ARIMA- .       ARIMA-.    (Statsoft 2021), (H. 2003), (Box J. 1974), (Hyndman 2018), (Hyndman 2021). 9.2 ts-        ts(),          .  .  ts_examples &lt;- ts(c(123,39,78,52,110), start=2017) autoplot(ts_examples) + ggtitle(&quot;Time series example&quot;) + ylab(&quot;$ million&quot;) + xlab(&quot;Year&quot;)         . 9.3        - autoplot(), ,    ,    ,     ,     .  ,      ts,         .       melsyd,      fpp2 (Hyndman 2018).         . data(melsyd) autoplot(melsyd[,&quot;Economy.Class&quot;]) + ggtitle(&quot;Economy class passengers: Melbourne-Sydney&quot;) + xlab(&quot;Year&quot;) + ylab(&quot;Thousands&quot;) autoplot(a10) + ggtitle(&quot;Antidiabetic drug sales&quot;) + ylab(&quot;$ million&quot;) + xlab(&quot;Year&quot;) #     # melsyd_economy &lt;- ansett %&gt;% # filter(Airports == &quot;MEL-SYD&quot;, Class == &quot;Economy&quot;) %&gt;% # mutate(Passengers = Passengers/1000) # # autoplot(melsyd_economy, Passengers) + # labs(title = &quot;Ansett airlines economy class&quot;, # subtitle = &quot;Melbourne-Sydney&quot;, # y = &quot;Passengers (&#39;000)&quot;)             . set.seed(30) y &lt;- ts(rnorm(50)) y %&gt;% autoplot() + ggtitle(&quot; &quot;)      . y %&gt;% ggAcf() y %&gt;% ggPacf() ,            . 9.4           . Which of these series are stationary? (a) Google stock price for 200 consecutive days; (b) Daily change in the Google stock price for 200 consecutive days; (c) Annual number of strikes in the US; (d) Monthly sales of new one-family houses sold in the US; (e) Annual price of a dozen eggs in the US (constant dollars); (f) Monthly total of pigs slaughtered in Victoria, Australia; (g) Annual total of lynx trapped in the McKenzie River district of north-west Canada; (h) Monthly Australian beer production; (i) Monthly Australian electricity production. (Hyndman 2018)         . goog200 %&gt;% autoplot() + ggtitle(&quot;  Google  200 &quot;) + ylab(&quot;goog200&quot;) + xlab(&quot;Day&quot;)    . goog200 %&gt;% ggAcf()          ,     . goog200 %&gt;% diff() %&gt;% autoplot()+ ggtitle(&quot;  Google  200 &quot;) + ylab(&quot;diff(goog200)&quot;) + xlab(&quot;Day&quot;)         ,     -. goog200 %&gt;% diff() %&gt;% ggAcf()   95%  ,   ,   Q-  - = 0,355 ( h=10).    ,      Google - ,  ,  ,        . goog200 %&gt;% diff() %&gt;% Box.test(lag=10, type=&quot;Ljung-Box&quot;) ## ## Box-Ljung test ## ## data: . ## X-squared = 11.031, df = 10, p-value = 0.3551 9.5     ARIMA-    (Hyndman 2018)         .    ,  , ,  ,       ARIMA. autoplot(uschange[,&quot;Consumption&quot;]) + xlab(&quot;Year&quot;) + ylab(&quot;Quarterly percentage change&quot;)    R,     . fit &lt;- auto.arima(uschange[,&quot;Consumption&quot;], seasonal=FALSE)    : \\[y_t = c + 0.589 y_{t-1} - 0.353 \\epsilon_{t-1} + 0.0846 \\epsilon_{t-2} + 0.174 \\epsilon_{t-3} + \\epsilon_t, \\]  \\(c = 0.745 × (1  0.589) = 0.307\\),  \\(\\epsilon_t\\)       \\(\\sigma = 0.592 = \\sqrt{0.350}\\).     . fit %&gt;% forecast(h=10) %&gt;% autoplot(include=80)       ,    . (fit2 &lt;- Arima(uschange[,&quot;Consumption&quot;], order=c(1,0,3))) ## Series: uschange[, &quot;Consumption&quot;] ## ARIMA(1,0,3) with non-zero mean ## ## Coefficients: ## ar1 ma1 ma2 ma3 mean ## 0.5885 -0.3528 0.0846 0.1739 0.7454 ## s.e. 0.1541 0.1658 0.0818 0.0843 0.0930 ## ## sigma^2 = 0.3499: log likelihood = -164.81 ## AIC=341.61 AICc=342.08 BIC=361 (fit3 &lt;- Arima(uschange[,&quot;Consumption&quot;], order=c(3,0,3))) ## Series: uschange[, &quot;Consumption&quot;] ## ARIMA(3,0,3) with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 ma1 ma2 ma3 mean ## 0.5145 0.4530 -0.3675 -0.2769 -0.3564 0.4576 0.7462 ## s.e. 0.3272 0.2457 0.2533 0.3111 0.2241 0.1678 0.0871 ## ## sigma^2 = 0.3514: log likelihood = -164.2 ## AIC=344.4 AICc=345.21 BIC=370.25 (fit4 &lt;- Arima(uschange[,&quot;Consumption&quot;], order=c(3,0,0))) ## Series: uschange[, &quot;Consumption&quot;] ## ARIMA(3,0,0) with non-zero mean ## ## Coefficients: ## ar1 ar2 ar3 mean ## 0.2274 0.1604 0.2027 0.7449 ## s.e. 0.0713 0.0723 0.0712 0.1029 ## ## sigma^2 = 0.3494: log likelihood = -165.17 ## AIC=340.34 AICc=340.67 BIC=356.5 9.6      ,  ,     .         ,   .               ARIMA-,   ,       \\(h\\)   .  .     .Rmd-   RNotebook. "]]
